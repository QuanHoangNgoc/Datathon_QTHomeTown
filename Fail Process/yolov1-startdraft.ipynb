{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7803789,"sourceType":"datasetVersion","datasetId":4569729}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"nice\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.809043Z","iopub.execute_input":"2024-03-10T01:03:16.809397Z","iopub.status.idle":"2024-03-10T01:03:16.814237Z","shell.execute_reply.started":"2024-03-10T01:03:16.809368Z","shell.execute_reply":"2024-03-10T01:03:16.813401Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"nice\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### global ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"torch\"\nimport tensorflow as tf\nimport torch \nimport keras\nprint(tf.__version__)\nprint(torch.__version__)\nprint(keras.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.816179Z","iopub.execute_input":"2024-03-10T01:03:16.816519Z","iopub.status.idle":"2024-03-10T01:03:16.829885Z","shell.execute_reply.started":"2024-03-10T01:03:16.816493Z","shell.execute_reply":"2024-03-10T01:03:16.829020Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"2.15.0\n2.1.2\n3.0.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nprint(np.__version__)\n# setting random_state\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)\ntf.random.set_seed(RANDOM_STATE)\ntorch.manual_seed(RANDOM_STATE)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.831012Z","iopub.execute_input":"2024-03-10T01:03:16.831277Z","iopub.status.idle":"2024-03-10T01:03:16.841365Z","shell.execute_reply.started":"2024-03-10T01:03:16.831245Z","shell.execute_reply":"2024-03-10T01:03:16.840499Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1.26.4\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c80c7f09290>"},"metadata":{}}]},{"cell_type":"markdown","source":"### some libraries and functions ","metadata":{}},{"cell_type":"code","source":"# libraries\nimport sys, os, math \nfrom collections import defaultdict\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.842508Z","iopub.execute_input":"2024-03-10T01:03:16.842783Z","iopub.status.idle":"2024-03-10T01:03:16.847536Z","shell.execute_reply.started":"2024-03-10T01:03:16.842759Z","shell.execute_reply":"2024-03-10T01:03:16.846608Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# fix random_state\ndef fixRandomState(fixed_state: int=RANDOM_STATE):\n  np.random.seed(fixed_state)\n  tf.random.set_seed(fixed_state)\n  torch.manual_seed(fixed_state)\n  \n# exception\ndef exception(requirement: bool, content):\n  if(requirement == False): raise ValueError(content)\ndef catchException(ex: Exception):\n  print(type(ex), ex.args)\n  exception(False, ex)\n\n# message\ndef mesVerbose(flag: bool, verbose, func_dir: str=\"\"):\n  if(flag == False): return\n  print(\"__verbose__:\", func_dir, verbose)\ndef mesWarning(note, func_dir: str=\"\"):\n  print(\"__warning__:\", func_dir, str(note) + \"$$$\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.850218Z","iopub.execute_input":"2024-03-10T01:03:16.850560Z","iopub.status.idle":"2024-03-10T01:03:16.859429Z","shell.execute_reply.started":"2024-03-10T01:03:16.850528Z","shell.execute_reply":"2024-03-10T01:03:16.858352Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def over(val) -> tuple:\n  try: mesVerbose(True, (type(val), val.shape, str(sys.getsizeof(val)) + \"Bytes\"), \"over:\")\n  except: mesVerbose(True, (type(val), \"no shape\", str(sys.getsizeof(val)) + \"Bytes\"), \"over:\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.860513Z","iopub.execute_input":"2024-03-10T01:03:16.860865Z","iopub.status.idle":"2024-03-10T01:03:16.866547Z","shell.execute_reply.started":"2024-03-10T01:03:16.860824Z","shell.execute_reply":"2024-03-10T01:03:16.865603Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class ModelHelp: \n  def plot(model, show_name: bool=False):\n    return keras.utils.plot_model(model,\n      show_layer_names=show_name, show_layer_activations=True,\n      show_shapes=True, show_dtype=True)\n\n  def debug(model):\n    model.summary(show_trainable=True)\n  \n  def getOutputAbs(model): \n    return model.layers[-1].output ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.867833Z","iopub.execute_input":"2024-03-10T01:03:16.868417Z","iopub.status.idle":"2024-03-10T01:03:16.877507Z","shell.execute_reply.started":"2024-03-10T01:03:16.868383Z","shell.execute_reply":"2024-03-10T01:03:16.876685Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"### model architecture ","metadata":{}},{"cell_type":"code","source":"from keras import Sequential, Input\nfrom keras.layers import (Conv2D, MaxPooling2D, Dense,\n                                  BatchNormalization, LeakyReLU, Dropout, Activation,\n                                  Flatten, Reshape)\n\nINPUT_SHAPE = (224, 224, 3)\n\nYOLO_BACKBONE_ARCHITECTURE = [(64, 7, 2, 'same'), 'M',\n                                (192, 3, 1, 'same'), 'M',\n                                (128, 1, 1, 'valid'),\n                                [(128, 256), 1],\n                                [(256, 512), 1], 'M',\n                                [(256, 512), 4],\n                                [(512, 1024), 1], 'M',\n                                [(512, 1024), 2]]","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.878622Z","iopub.execute_input":"2024-03-10T01:03:16.878985Z","iopub.status.idle":"2024-03-10T01:03:16.886189Z","shell.execute_reply.started":"2024-03-10T01:03:16.878960Z","shell.execute_reply":"2024-03-10T01:03:16.885239Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"##### blcoks","metadata":{}},{"cell_type":"code","source":"class ConvWithBatchNorm(Sequential):\n  \"\"\"Conv layer with batch norm and leaky relu\"\"\"\n  \n  def __init__(self, filters=64, kernel_size=3, strides=1, padding='same',\n                activation=LeakyReLU(alpha=0.1), kernel_regularizer=None,\n                name='conv', **kwargs):\n    layers = [Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,\n                        padding=padding, activation=None,\n                        kernel_regularizer=kernel_regularizer, name=name, **kwargs)]\n    # adding Layers together\n    layers += [BatchNormalization(name=name + '_bn')]\n    layers += [Activation(activation, name=name + '_act')]\n    # inher customize\n    super().__init__(layers=layers, name=name)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:16.994947Z","iopub.execute_input":"2024-03-10T01:03:16.995318Z","iopub.status.idle":"2024-03-10T01:03:17.003652Z","shell.execute_reply.started":"2024-03-10T01:03:16.995289Z","shell.execute_reply":"2024-03-10T01:03:17.002671Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class BottleNeckBlock(Sequential):\n  \"\"\"Block of 1x1 reduction layers followed by 3x3 conv. layer\"\"\"\n  \n  def __init__(self, filters, repetitions, name='bottleneck_block', **kwargs):\n    filters_1x1 = filters[0]\n    filters_3x3 = filters[1]\n    model = []\n    for i in range(repetitions):\n        model += [ConvWithBatchNorm(filters=filters_1x1, kernel_size=1,\n                                    strides=1, padding='valid',\n                                    name='{}_conv_1x1_{}'.format(name, i + 1), **kwargs)]\n        model += [ConvWithBatchNorm(filters=filters_3x3, kernel_size=3,\n                                    strides=1, padding='same',\n                                    name='{}_conv_3x3_{}'.format(name, i + 1), **kwargs)]\n    ### inher customize\n    super().__init__(layers=model, name=name)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:17.005586Z","iopub.execute_input":"2024-03-10T01:03:17.006272Z","iopub.status.idle":"2024-03-10T01:03:17.015158Z","shell.execute_reply.started":"2024-03-10T01:03:17.006227Z","shell.execute_reply":"2024-03-10T01:03:17.013873Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"##### YoloBackbone","metadata":{}},{"cell_type":"code","source":"class YoloBackbone(Sequential):\n  \"\"\"YOLO backbone extract feature from the input\"\"\"\n\n  def __init__(self, input_shape=INPUT_SHAPE, backbone_config=YOLO_BACKBONE_ARCHITECTURE, name='YOLO_Backbone'):\n    ### input_abstration \n    model = [keras.Input(shape=INPUT_SHAPE)]\n    \n    for i, config in enumerate(backbone_config):\n        if type(config) == tuple:\n          filters, kernel_size, strides, padding = config\n          model += [ConvWithBatchNorm(filters, kernel_size, strides, padding,\n                                      name='backbone_conv_{}'.format(i + 1))]\n        elif type(config) == str:\n          model += [MaxPooling2D(pool_size=2, strides=2, padding='same',\n                                  name='backbone_max_pooling_{}'.format(i + 1))]\n        elif type(config) == list:\n          filters, repetition = config\n          model += [BottleNeckBlock(filters, repetition,\n                                    name='backbone_bottleneck_block_{}'.format(i + 1))]\n    ### inher customize\n    super().__init__(layers=model, name=name)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:17.016464Z","iopub.execute_input":"2024-03-10T01:03:17.016827Z","iopub.status.idle":"2024-03-10T01:03:17.026727Z","shell.execute_reply.started":"2024-03-10T01:03:17.016794Z","shell.execute_reply":"2024-03-10T01:03:17.025862Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"ModelHelp.debug(YoloBackbone())","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:17.028007Z","iopub.execute_input":"2024-03-10T01:03:17.028310Z","iopub.status.idle":"2024-03-10T01:03:17.602320Z","shell.execute_reply.started":"2024-03-10T01:03:17.028284Z","shell.execute_reply":"2024-03-10T01:03:17.601352Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"YOLO_Backbone\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"YOLO_Backbone\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n│ backbone_conv_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m9,728\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_conv_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │    \u001b[38;5;34m111,552\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_conv_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m25,216\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m313,216\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mBottleNeckBlock\u001b[0m)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,249,024\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mBottleNeckBlock\u001b[0m)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_8      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_9 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m5,258,240\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mBottleNeckBlock\u001b[0m)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)  │  \u001b[38;5;34m4,988,416\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mBottleNeckBlock\u001b[0m)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_11     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)    │ \u001b[38;5;34m10,501,120\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mBottleNeckBlock\u001b[0m)           │                       │            │       │\n└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n│ backbone_conv_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,728</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_conv_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">111,552</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_conv_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,216</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">313,216</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BottleNeckBlock</span>)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,249,024</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BottleNeckBlock</span>)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_8      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_9 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,258,240</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BottleNeckBlock</span>)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,988,416</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BottleNeckBlock</span>)           │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_max_pooling_11     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)              │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ backbone_bottleneck_block_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">10,501,120</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BottleNeckBlock</span>)           │                       │            │       │\n└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,456,512\u001b[0m (85.66 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,456,512</span> (85.66 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,438,080\u001b[0m (85.59 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,438,080</span> (85.59 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m18,432\u001b[0m (72.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> (72.00 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"##### YoloOutput ","metadata":{}},{"cell_type":"code","source":"class YoloOutput(Sequential):\n  \"\"\"YOLO last convolution and FC layers to produce prediction\"\"\"\n\n  def __init__(self, grid_size=7, num_boxes=2, num_classes=20, name='YOLO_Output'):\n    # input_abstraction \n    input_abs = ModelHelp.getOutputAbs(YoloBackbone()) \n    yolo_output = [keras.Input(shape=input_abs.shape[1:])]\n    \n    S, B, C = grid_size, num_boxes, num_classes\n    yolo_output += [ConvWithBatchNorm(filters=1024, kernel_size=3, strides=1,\n                                      padding='same', name='output_conv_1'),\n                    ConvWithBatchNorm(filters=1024, kernel_size=3, strides=2,\n                                      padding='same', name='output_conv_2'),\n                    ConvWithBatchNorm(filters=1024, kernel_size=3, strides=1,\n                                      padding='same', name='output_conv_3'),\n                    ConvWithBatchNorm(filters=1024, kernel_size=3, strides=1,\n                                      padding='same', name='output_conv_4'),\n                    Flatten(),\n                    Dense(units=4096, activation=LeakyReLU(alpha=0.1), name='output_fc_1'),\n                    Dropout(rate=0.5, name='dropout_1'),\n                    Dense(units=2048, activation=LeakyReLU(alpha=0.1), name='output_fc_2'),\n                    Dropout(rate=0.5, name='dropout_2'),\n                    Dense(units=1024, activation=LeakyReLU(alpha=0.1), name='output_fc_3'),\n                    Dropout(rate=0.5, name='dropout_3'),\n                    Dense(units=S * S * (B * 5 + C), name='prediction')]\n    ### inher customize\n    super().__init__(layers=yolo_output, name=name)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:17.605540Z","iopub.execute_input":"2024-03-10T01:03:17.605831Z","iopub.status.idle":"2024-03-10T01:03:17.617156Z","shell.execute_reply.started":"2024-03-10T01:03:17.605805Z","shell.execute_reply":"2024-03-10T01:03:17.616214Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(YoloBackbone())\nprint(ModelHelp.getOutputAbs(YoloBackbone())) ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:17.618750Z","iopub.execute_input":"2024-03-10T01:03:17.619465Z","iopub.status.idle":"2024-03-10T01:03:18.028201Z","shell.execute_reply.started":"2024-03-10T01:03:17.619423Z","shell.execute_reply":"2024-03-10T01:03:18.027330Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"<YoloBackbone name=YOLO_Backbone, built=True>\n<KerasTensor shape=(None, 7, 7, 1024), dtype=float32, sparse=False, name=keras_tensor_360>\n","output_type":"stream"}]},{"cell_type":"code","source":"ModelHelp.debug(YoloOutput())","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:18.029245Z","iopub.execute_input":"2024-03-10T01:03:18.029521Z","iopub.status.idle":"2024-03-10T01:03:18.301793Z","shell.execute_reply.started":"2024-03-10T01:03:18.029497Z","shell.execute_reply":"2024-03-10T01:03:18.300937Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"YOLO_Output\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"YOLO_Output\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n│ output_conv_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)    │  \u001b[38;5;34m9,442,304\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_conv_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)    │  \u001b[38;5;34m9,442,304\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_conv_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)    │  \u001b[38;5;34m9,442,304\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_conv_4               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)    │  \u001b[38;5;34m9,442,304\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n│ (\u001b[38;5;33mConvWithBatchNorm\u001b[0m)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_fc_1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)          │ \u001b[38;5;34m67,112,960\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_fc_2 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │  \u001b[38;5;34m8,390,656\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_fc_3 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │  \u001b[38;5;34m2,098,176\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │   \u001b[1m-\u001b[0m   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ prediction (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1470\u001b[0m)          │  \u001b[38;5;34m1,506,750\u001b[0m │   \u001b[1;38;5;34mY\u001b[0m   │\n└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                </span>┃<span style=\"font-weight: bold\"> Output Shape          </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩\n│ output_conv_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,442,304</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_conv_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,442,304</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_conv_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,442,304</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_conv_4               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,442,304</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvWithBatchNorm</span>)         │                       │            │       │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_fc_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)          │ <span style=\"color: #00af00; text-decoration-color: #00af00\">67,112,960</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_fc_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,390,656</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ output_fc_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │   <span style=\"font-weight: bold\">-</span>   │\n├─────────────────────────────┼───────────────────────┼────────────┼───────┤\n│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1470</span>)          │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,506,750</span> │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n└─────────────────────────────┴───────────────────────┴────────────┴───────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m116,877,758\u001b[0m (445.85 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,877,758</span> (445.85 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m116,869,566\u001b[0m (445.82 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,869,566</span> (445.82 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,192\u001b[0m (32.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> (32.00 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"##### YoloV1 ","metadata":{}},{"cell_type":"code","source":"class YoloV1(Sequential):\n  \"\"\"End-to-end YOLO network\"\"\"\n\n  def __init__(self, input_shape=INPUT_SHAPE, grid_size=7, num_boxes=2, num_classes=20,\n                backbone_config=YOLO_BACKBONE_ARCHITECTURE, name='YOLO_V1'):\n    S, B, C = grid_size, num_boxes, num_classes\n    yolo_backbone = YoloBackbone(input_shape=input_shape, backbone_config=backbone_config)\n    yolo_output = YoloOutput(grid_size=S, num_boxes=B, num_classes=C)\n    ### only can adding together, not can store atribute (state) before super() constructor is called\n    layers = [keras.Input(shape=INPUT_SHAPE)]\n    layers += [yolo_backbone, yolo_output]\n    layers += [Reshape((S, S, (5 * B + C)))]\n    ### inher customize\n    super().__init__(layers=layers, name=name)\n    self.a = yolo_backbone\n    self.b = yolo_output\n    self.S, self.B, self.C = S, B, C \n    \n  def call(self, inputs: torch.Tensor, training=False) -> torch.Tensor:\n    output = super().call(inputs=inputs, training=training) \n    # torch.tensor(output.numpy()) # convert output to tensor \n    # over(output) # but output is torch.Tensor\n    if training:\n        return output\n    return output ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:12:16.030149Z","iopub.execute_input":"2024-03-10T01:12:16.030541Z","iopub.status.idle":"2024-03-10T01:12:16.042109Z","shell.execute_reply.started":"2024-03-10T01:12:16.030510Z","shell.execute_reply":"2024-03-10T01:12:16.041056Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### YoloLoss ","metadata":{}},{"cell_type":"code","source":"from keras.losses import Loss \nclass YoloLoss(Loss): \n  def __init__(self, coord_c=5, noobj_c=0.5): \n    super().__init__()\n    self.COORD = coord_c\n    self.NOOBJ = noobj_c \n  \n  def expDim(self, val, unsque): \n    return torch.tensor(val, dtype=torch.float32).unsqueeze(unsque)\n    \n  def computeArea(self, a, b, c, d): \n    return (c-a) * (d-b) \n  def computeIOU(self, cell, cell0): \n    x, y, w, h = cell[..., [0]], cell[..., [1]], cell[..., [2]], cell[..., [3]] \n    x0, y0, w0, h0 = cell0[..., [0]], cell0[..., [1]], cell0[..., [2]], cell0[..., [3]]  \n    a, b, c, d = torch.min(x-w, x0-w0), torch.min(y-h, y0-h0), torch.max(x+w, x0+w0), torch.max(y+h, y0+h0)\n    return self.computeArea(a, b, c, d) / (self.computeArea(x-w, y-h, x+w, y+h) + self.computeArea(x0-w0, y0-h0, x0+w0, y0+w0) - self.computeArea(a, b, c, d))\n  \n  def computeCoorLoss(self, O, mask0, cell, cell0): \n    x, y, w, h = cell[..., [0]], cell[..., [1]], cell[..., [2]], cell[..., [3]] \n    x0, y0, w0, h0 = cell0[..., [0]], cell0[..., [1]], cell0[..., [2]], cell0[..., [3]]  \n    return torch.sum(O * mask0 * (x-x0)**2 + (y-y0)**2) + torch.sum(O * mask0 * (w**0.5-w0**0.5)**2 + (h**0.5-h0**0.5)**2)\n  \n  def call(self, y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor: \n    cell = y_true[..., :4] # (N, S, S, 4)\n    O = y_true[..., [4]]\n    # O = self.expDim(y_true[..., 4], 3) # (N, S, S, 1) \n    P = y_true[..., 5:] # (N, S, S, C)\n    N = y_true.shape[0] \n\n    cell1 = y_pred[..., :4]\n    O1 = y_pred[..., [4]]\n    # O1 = self.expDim(y_pred[..., 4], 3) \n    cell2 = y_pred[..., 5:9]\n    O2 = y_pred[..., [9]]\n    # O2 = self.expDim(y_pred[..., 9], 3) \n    P0 = y_pred[..., 10:]\n\n    classloss = torch.sum(O * (P - P0)**2)  \n    #print(classloss) \n    \n    iou1 = self.computeIOU(cell=cell, cell0=cell1)\n    iou2 = self.computeIOU(cell=cell, cell0=cell2) \n    mask1 = torch.where(iou1 > iou2, 1, 0)\n    mask2 = torch.where(iou1 < iou2, 1, 0) \n    coorloss = self.computeCoorLoss(O, mask1, cell, cell1) + self.computeCoorLoss(O, mask2, cell, cell2) \n    coorloss *= self.COORD    \n    #print(coorloss) \n    objloss = torch.sum(O * mask1 * (O-O1)**2) + torch.sum(O * mask2 * (O-O2)**2)\n    #print(objloss)\n    noobjloss = torch.sum((1-O) * (O-O1)**2 + (1-O) * (O-O2)**2)\n    noobjloss *= self.NOOBJ \n    # print(noobjloss) \n    return (classloss + coorloss + objloss + noobjloss) / N \n  ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:18.314040Z","iopub.execute_input":"2024-03-10T01:03:18.314331Z","iopub.status.idle":"2024-03-10T01:03:18.335201Z","shell.execute_reply.started":"2024-03-10T01:03:18.314307Z","shell.execute_reply":"2024-03-10T01:03:18.334326Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:16:27.351011Z","iopub.execute_input":"2024-03-10T01:16:27.351378Z","iopub.status.idle":"2024-03-10T01:16:27.356146Z","shell.execute_reply.started":"2024-03-10T01:16:27.351349Z","shell.execute_reply":"2024-03-10T01:16:27.355156Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"imgs = torch.rand(16, 224, 224, 3).to(DEVICE) \nmodel = YoloV1()\nout = model(imgs) \nover(out) ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:16:29.718659Z","iopub.execute_input":"2024-03-10T01:16:29.719019Z","iopub.status.idle":"2024-03-10T01:16:30.233362Z","shell.execute_reply.started":"2024-03-10T01:16:29.718991Z","shell.execute_reply":"2024-03-10T01:16:30.232390Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"__verbose__: over: (<class 'torch.Tensor'>, torch.Size([16, 7, 7, 30]), '80Bytes')\n","output_type":"stream"}]},{"cell_type":"code","source":"out_true = torch.rand(16, 7, 7, 25).to(DEVICE) \nover(out_true) \n# print(out_true)\nloss = YoloLoss()\nloss.call(y_pred=out, y_true=out_true) ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:16:51.245190Z","iopub.execute_input":"2024-03-10T01:16:51.245572Z","iopub.status.idle":"2024-03-10T01:16:51.623780Z","shell.execute_reply.started":"2024-03-10T01:16:51.245541Z","shell.execute_reply":"2024-03-10T01:16:51.622894Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"__verbose__: over: (<class 'torch.Tensor'>, torch.Size([16, 7, 7, 25]), '80Bytes')\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"tensor(nan, device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### DataLoad","metadata":{}},{"cell_type":"code","source":"import os\nfrom xml.etree import ElementTree\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom functools import partial\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom torch.utils.data import Dataset, DataLoader\n\nclass_names = ['apple', 'banana', 'orange']\n\nclass DataLoad(Dataset): \n  def __init__(self, file_dir, input_shape, grid_size=7) -> None:\n    super().__init__ \n    dataframe = self.get_dataframe(file_dir=file_dir)\n    self.imgs, self.labels = self.load_dataset(dataframe, input_shape, grid_size) # np.ndarray \n  \n  def __len__(self):\n    return len(self.imgs)\n\n  def __getitem__(self, idx): #!!! get data \n      x, y = self.imgs, self.labels # np.ndarray \n      x, y = self._apply_augmentation(x, y, seed=RANDOM_STATE) # tf.tensor \n      # cast type \n      x = torch.tensor(x, dtype=torch.float32).unsqueeze(0)  # torch.tensor \n      y = torch.tensor(y, dtype=torch.float32).unsqueeze(0) \n      x, y = x.to(DEVICE), y.to(DEVICE) # torch.tensor.device \n      # over(x)\n      # over(y) \n      return x, y\n  \n  \n  def get_dataframe(self, file_dir):\n    \"\"\"\n    Get the train/val/test dataframe which contains image\n    file names and annotations files. If `phase = train',\n    return train and val set\n    :param file_dir: File directory to create dataframe\n    :return file_df: Train or test dataframe\n    \"\"\"\n\n    img_files = [os.path.join(file_dir, img_file) for img_file\n                 in sorted(os.listdir(file_dir)) if img_file[-4:] == '.jpg']\n    annot_files = [img_file[:-4] + '.xml' for img_file in img_files]\n\n    img_file_series = pd.Series(img_files, name='Image_file')\n    annot_file_series = pd.Series(annot_files, name='Annotation_file')\n    file_df = pd.DataFrame(pd.concat([img_file_series, annot_file_series], axis=1))\n\n    return file_df\n\n  def prepare_image(self, filename, input_shape):\n    \"\"\"\n    Resize image to expected dimension, and opt. apply some random transformation.\n    :param filename: File name\n    :param input_shape: Shape expected by the model (image will be resize accordingly)\n    :return : 3D image array, pixel values from [0., 1.]\n    \"\"\"\n\n    img = img_to_array(load_img(filename, target_size=input_shape)) / 255.\n\n    return img\n\n  def convert_to_xywh(self, bboxes):\n    \"\"\"\n    Convert list of (xmin, ymin, xmax, ymax) to\n    (x_center, y_center, box_width, box_height)\n    :param bboxes: List of bounding boxes, each has 4\n    values (xmin, ymin, xmax, ymax)\n    :return boxes: List of bounding boxes, each has 4\n    values (x_center, y_center, box_width, box_height)\n    \"\"\"\n\n    boxes = list()\n    for box in bboxes:\n        xmin, ymin, xmax, ymax = box\n\n        # Compute width and height of box\n        box_width = xmax - xmin\n        box_height = ymax - ymin\n\n        # Compute x, y center\n        x_center = int(xmin + (box_width / 2))\n        y_center = int(ymin + (box_height / 2))\n\n        boxes.append((x_center, y_center, box_width, box_height))\n\n    return boxes\n\n  def extract_annotation_file(self, filename):\n    \"\"\"\n    Extract bounding boxes from an annotation file\n    :param filename: Annotation file name\n    :return boxes: List of bounding boxes in image, each box has\n    4 values (x_center, y_center, box_width, box_height)\n    :return classes: List of classes in image\n    :return width: Width of image\n    :return height: Height of image\n    \"\"\"\n\n    # Load and parse the file\n    tree = ElementTree.parse(filename)\n    # Get the root of the document\n    root = tree.getroot()\n    boxes = list()\n    classes = list()\n\n    # Extract each bounding box\n    for box in root.findall('.//object'):\n        cls = class_names.index(box.find('name').text)\n        xmin = int(box.find('bndbox/xmin').text)\n        ymin = int(box.find('bndbox/ymin').text)\n        xmax = int(box.find('bndbox/xmax').text)\n        ymax = int(box.find('bndbox/ymax').text)\n        coors = (xmin, ymin, xmax, ymax)\n        boxes.append(coors)\n        classes.append(cls)\n\n    boxes = self.convert_to_xywh(boxes)\n\n    # Get width and height of an image\n    width = int(root.find('.//size/width').text)\n    height = int(root.find('.//size/height').text)\n\n    # Some annotation files have set width and height by 0,\n    # so we need to load image and get it width and height\n    if (width == 0) or (height == 0):\n        img = load_img(filename[:-4] + '.jpg')\n        width, height = img.width, img.height\n\n    return boxes, classes, width, height\n\n  def convert_bboxes_to_tensor(self, bboxes, classes, img_width, img_height, grid_size=7):\n    \"\"\"\n    Convert list of bounding boxes to tensor target\n    :param bboxes: List of bounding boxes in image, each box has\n    4 values (x_center, y_center, box_width, box_height)\n    :param classes: List of class in image\n    :param img_width: Image's width\n    :param img_height: Image's height\n    :param grid_size: Grid size\n    :return target: Target tensor (grid_size x grid_size x (5 + num_classes))\n    \"\"\"\n\n    num_classes = len(class_names)\n    target = np.zeros(shape=(grid_size, grid_size, 5 + num_classes), dtype=np.float32)\n\n    for idx, bbox in enumerate(bboxes):\n        x_center, y_center, width, height = bbox\n\n        # Compute size of each cell in grid\n        cell_w, cell_h = img_width / grid_size, img_height / grid_size\n\n        # Determine cell i, j of bounding box\n        i, j = int(y_center / cell_h), int(x_center / cell_w)\n\n        # Compute value of x_center and y_center in cell\n        x, y = (x_center / cell_w) - j, (y_center / cell_h) - i\n\n        # Normalize width and height of bounding box\n        w_norm, h_norm = width / img_width, height / img_height\n\n        # Add bounding box to tensor\n        # Set x, y, w, h\n        target[i, j, :4] += (x, y, w_norm, h_norm)\n        # Set obj score\n        target[i, j, 4] = 1.\n        # Set class dist.\n        target[i, j, 5 + classes[idx]] = 1.\n\n    return target\n\n  def load_dataset(self, dataframe, input_shape, grid_size=7):\n    \"\"\"\n    Load img and target tensor\n    :param dataframe: Dataframe contains img files and annotation files\n    :param input_shape: Shape expected by the model (image will be resize accordingly)\n    :param grid_size: Grid size\n    :return dataset: Iterable dataset\n    \"\"\"\n\n    imgs, targets = list(), list()\n\n    for _, row in tqdm(dataframe.iterrows()):\n        img = self.prepare_image(row.Image_file, input_shape)\n        target = self.extract_annotation_file(row.Annotation_file)\n        target = self.convert_bboxes_to_tensor(*target, grid_size)\n        imgs.append(img)\n        targets.append(target)\n\n    imgs = np.array(imgs)\n    targets = np.array(targets)\n    return imgs, targets \n  \n    # dataset = tf.data.Dataset.from_tensor_slices((imgs, targets))\n    # return dataset\n\n\n  def _apply_augmentation(self, image, target, seed=None):\n    \"\"\"\n    Apply random brightness and saturation on image\n    :param image: Image to augment\n    :param target: Target tensor\n    :param seed: Seed for random operation\n    :return : Processed data\n    \"\"\"\n\n    # Random bright & saturation change\n    image = tf.image.random_brightness(image, max_delta=0.1, seed=seed)\n    image = tf.image.random_saturation(image, lower=0.5, upper=1.5, seed=seed)\n\n    # Keeping pixel values in check\n    image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n\n    return image, target\n\n\n  def load_dataset_from_df(self, dataframe, batch_size=32, num_repeat=None, shuffle=False,\n                         input_shape=(448, 448, 3), grid_size=7, augment=False,\n                         seed=None):\n    \"\"\"\n    Instantiate dataset\n    :param dataframe: Dataframe contains img files and annotation files\n    :param batch_size: Batch size\n    :param num_epochs: Number of epochs (to repeat the iteration - infinite if None)\n    :param shuffle: Flag to shuffle the dataset (if True)\n    :param input_shape: Shape of the processed image\n    :param grid_size: Grid size\n    :param augment: Flag to apply some random augmentations to the image\n    :param seed: Random seed for operation\n    :return : Iterable dataset\n    \"\"\"\n\n    apply_augmentation = partial(self._apply_augmentation, seed=seed)\n\n    dataset = self.load_dataset(dataframe, input_shape, grid_size)\n    ### !!!\n    dataset = dataset.repeat(num_repeat)\n    if shuffle:\n        dataset = dataset.shuffle(1000, seed)\n    if augment:\n        dataset = dataset.map(apply_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:26:16.026113Z","iopub.execute_input":"2024-03-10T01:26:16.026649Z","iopub.status.idle":"2024-03-10T01:26:16.071928Z","shell.execute_reply.started":"2024-03-10T01:26:16.026619Z","shell.execute_reply":"2024-03-10T01:26:16.070926Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_dir = './fruits_dataset/train'\ninput_shape = (448, 448, 3)\ngrid_size = 7\nnum_repeat = 2\nbatch_size = 16\ndataload = DataLoad(train_dir, input_shape=(448, 448, 3), grid_size=7) \ntrain_df = dataload.get_dataframe(train_dir)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:26:32.748149Z","iopub.execute_input":"2024-03-10T01:26:32.748804Z","iopub.status.idle":"2024-03-10T01:26:32.865414Z","shell.execute_reply.started":"2024-03-10T01:26:32.748774Z","shell.execute_reply":"2024-03-10T01:26:32.864305Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m num_repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m----> 6\u001b[0m dataload \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m448\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m448\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m train_df \u001b[38;5;241m=\u001b[39m dataload\u001b[38;5;241m.\u001b[39mget_dataframe(train_dir)\n","Cell \u001b[0;32mIn[51], line 14\u001b[0m, in \u001b[0;36mDataLoad.__init__\u001b[0;34m(self, file_dir, input_shape, grid_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_dir, input_shape, grid_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \n\u001b[0;32m---> 14\u001b[0m   dataframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_dataset(dataframe, input_shape, grid_size)\n","Cell \u001b[0;32mIn[51], line 42\u001b[0m, in \u001b[0;36mDataLoad.get_dataframe\u001b[0;34m(self, file_dir)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_dir):\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m  Get the train/val/test dataframe which contains image\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m  file names and annotations files. If `phase = train',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m  :return file_df: Train or test dataframe\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m   img_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(file_dir, img_file) \u001b[38;5;28;01mfor\u001b[39;00m img_file\n\u001b[0;32m---> 42\u001b[0m                \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_dir\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m img_file[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m:] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     43\u001b[0m   annot_files \u001b[38;5;241m=\u001b[39m [img_file[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xml\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_file \u001b[38;5;129;01min\u001b[39;00m img_files]\n\u001b[1;32m     45\u001b[0m   img_file_series \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(img_files, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage_file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fruits_dataset/train'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './fruits_dataset/train'","output_type":"error"}]},{"cell_type":"code","source":"over(dataload) ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:26:24.232230Z","iopub.execute_input":"2024-03-10T01:26:24.233152Z","iopub.status.idle":"2024-03-10T01:26:24.271709Z","shell.execute_reply.started":"2024-03-10T01:26:24.233117Z","shell.execute_reply":"2024-03-10T01:26:24.270598Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m over(\u001b[43mdataload\u001b[49m) \n","\u001b[0;31mNameError\u001b[0m: name 'dataload' is not defined"],"ename":"NameError","evalue":"name 'dataload' is not defined","output_type":"error"}]},{"cell_type":"code","source":"over(dataload[0][1]) ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:20.008585Z","iopub.status.idle":"2024-03-10T01:03:20.009060Z","shell.execute_reply.started":"2024-03-10T01:03:20.008801Z","shell.execute_reply":"2024-03-10T01:03:20.008820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming train_dataset is your training dataset\ntrain_loader = DataLoader(dataset=dataload, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, drop_last=True, prefetch_factor=2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:20.010431Z","iopub.status.idle":"2024-03-10T01:03:20.010885Z","shell.execute_reply.started":"2024-03-10T01:03:20.010633Z","shell.execute_reply":"2024-03-10T01:03:20.010650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### training and testing ","metadata":{}},{"cell_type":"code","source":"train_steps_per_epoch = math.ceil(len(train_df) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:20.012481Z","iopub.status.idle":"2024-03-10T01:03:20.012926Z","shell.execute_reply.started":"2024-03-10T01:03:20.012680Z","shell.execute_reply":"2024-03-10T01:03:20.012699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolov1 = YoloV1()\nyolov1.compile(loss=YoloLoss(), optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:20.014124Z","iopub.status.idle":"2024-03-10T01:03:20.014794Z","shell.execute_reply.started":"2024-03-10T01:03:20.014545Z","shell.execute_reply":"2024-03-10T01:03:20.014564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists('weights'):\n    os.mkdir('weights')\n\n\n# checkpoint_path = './weights/yolo_best_weights.hdf5'\n\n\n# checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n#                                                 save_weights_only=True,\n#                                                 verbose=1,\n#                                                 save_best_only=True,\n#                                                 monitor='loss')\n\n# early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=300,\n#                                               restore_best_weights=True)\n\nhist = yolov1.fit(train_loader, epochs=500, verbose=1, steps_per_epoch=train_steps_per_epoch) ","metadata":{"execution":{"iopub.status.busy":"2024-03-10T01:03:20.016029Z","iopub.status.idle":"2024-03-10T01:03:20.016764Z","shell.execute_reply.started":"2024-03-10T01:03:20.016520Z","shell.execute_reply":"2024-03-10T01:03:20.016540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### End ","metadata":{}}]}