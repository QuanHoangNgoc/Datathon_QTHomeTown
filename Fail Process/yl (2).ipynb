{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:51.435671Z",
          "iopub.status.busy": "2024-03-10T03:46:51.434958Z",
          "iopub.status.idle": "2024-03-10T03:46:51.447220Z",
          "shell.execute_reply": "2024-03-10T03:46:51.446250Z",
          "shell.execute_reply.started": "2024-03-10T03:46:51.435639Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vymEjuKIk4pd",
        "outputId": "f43c8496-3b88-4698-aafc-f640278d0eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ],
      "source": [
        "print(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMCb_MwNk4pf"
      },
      "source": [
        "### global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:51.449179Z",
          "iopub.status.busy": "2024-03-10T03:46:51.448900Z",
          "iopub.status.idle": "2024-03-10T03:46:58.091874Z",
          "shell.execute_reply": "2024-03-10T03:46:58.090861Z",
          "shell.execute_reply.started": "2024-03-10T03:46:51.449158Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjC16i_mk4pi",
        "outputId": "d2f057df-b6d6-4534-a7f5-80cad2abc6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "print(tf.__version__)\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.095890Z",
          "iopub.status.busy": "2024-03-10T03:46:58.095283Z",
          "iopub.status.idle": "2024-03-10T03:46:58.105202Z",
          "shell.execute_reply": "2024-03-10T03:46:58.104215Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.095854Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf2_vC6Kk4pj",
        "outputId": "0150f0ee-2934-4080-a25a-383aa7018bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d5a71a47450>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "# setting random_state\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "torch.manual_seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db9CUa5Ek4pl"
      },
      "source": [
        "### some libraries and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.107279Z",
          "iopub.status.busy": "2024-03-10T03:46:58.106432Z",
          "iopub.status.idle": "2024-03-10T03:46:58.452054Z",
          "shell.execute_reply": "2024-03-10T03:46:58.451227Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.107253Z"
        },
        "trusted": true,
        "id": "r7nwh0e_k4pm"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import sys, math\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.454862Z",
          "iopub.status.busy": "2024-03-10T03:46:58.454295Z",
          "iopub.status.idle": "2024-03-10T03:46:58.462716Z",
          "shell.execute_reply": "2024-03-10T03:46:58.461718Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.454817Z"
        },
        "trusted": true,
        "id": "om06RJL2k4pm"
      },
      "outputs": [],
      "source": [
        "# fix random_state\n",
        "def fixRandomState(fixed_state: int=RANDOM_STATE):\n",
        "  np.random.seed(fixed_state)\n",
        "  tf.random.set_seed(fixed_state)\n",
        "  torch.manual_seed(fixed_state)\n",
        "\n",
        "# exception\n",
        "def exception(requirement: bool, content):\n",
        "  if(requirement == False): raise ValueError(content)\n",
        "def catchException(ex: Exception):\n",
        "  print(type(ex), ex.args)\n",
        "  exception(False, ex)\n",
        "\n",
        "# message\n",
        "def mesVerbose(flag: bool, verbose, func_dir: str=\"\"):\n",
        "  if(flag == False): return\n",
        "  print(\"__verbose__:\", func_dir, verbose)\n",
        "def mesWarningToUser(note, func_dir: str=\"\"):\n",
        "  print(\"__warning__:\", func_dir, str(note) + \"&&&\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.464382Z",
          "iopub.status.busy": "2024-03-10T03:46:58.464053Z",
          "iopub.status.idle": "2024-03-10T03:46:58.472781Z",
          "shell.execute_reply": "2024-03-10T03:46:58.471931Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.464349Z"
        },
        "trusted": true,
        "id": "1lElqLSLk4pn"
      },
      "outputs": [],
      "source": [
        "def over(val, name=\"\") -> tuple:\n",
        "  try: mesVerbose(True, (type(val), val.shape, str(sys.getsizeof(val)) + \"Bytes\"), name)\n",
        "  except: mesVerbose(True, (type(val), \"no-shape\", str(sys.getsizeof(val)) + \"Bytes\"), name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSU76Uxgk4po"
      },
      "source": [
        "### model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.485961Z",
          "iopub.status.busy": "2024-03-10T03:46:58.485664Z",
          "iopub.status.idle": "2024-03-10T03:46:58.493427Z",
          "shell.execute_reply": "2024-03-10T03:46:58.492461Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.485938Z"
        },
        "trusted": true,
        "id": "LXmFP8FWk4pp"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "IN_SHAPE = (BATCH_SIZE, 3, 224, 224)\n",
        "\n",
        "YOLO_BACKBONE_ARCHITECTURE = [(64, 7, 2, 'same'), 'M',\n",
        "                                (192, 3, 1, 'same'), 'M',\n",
        "                                (128, 1, 1, 'valid'),\n",
        "                                [(128, 256), 1],\n",
        "                                [(256, 512), 1], 'M',\n",
        "                                [(256, 512), 4],\n",
        "                                [(512, 1024), 1], 'M',\n",
        "                                [(512, 1024), 2]]\n",
        "\n",
        "GRID_SIZE = 7\n",
        "NUM_BOXES = 2\n",
        "NUM_CLASSES = 3\n",
        "OUT_SHAPE = (BATCH_SIZE, 7, 7, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:47:00.016141Z",
          "iopub.status.busy": "2024-03-10T03:47:00.015793Z",
          "iopub.status.idle": "2024-03-10T03:47:00.025351Z",
          "shell.execute_reply": "2024-03-10T03:47:00.024521Z",
          "shell.execute_reply.started": "2024-03-10T03:47:00.016112Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SZN5eJek4pv",
        "outputId": "a12ecf46-47e8-40e1-8ab4-3c4c16fd3998"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### nnModule"
      ],
      "metadata": {
        "id": "5bdgFDackvjY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "QXDFK-vck4pr"
      },
      "outputs": [],
      "source": [
        "class nnModule(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super(nnModule, self).__init__()\n",
        "    self.in_shape = ()\n",
        "    self.out_shape = ()\n",
        "    self.model = nn.ModuleList()\n",
        "\n",
        "  def getInShape(self): return self.in_shape\n",
        "  def getOutShape(self): return self.out_shape\n",
        "  def getModel(self): return self.model\n",
        "  def setInShape(self, in_shape): self.in_shape = in_shape\n",
        "  def setOutShape(self, out_shape): self.out_shape = out_shape\n",
        "  def setModel(self, model): self.model = model\n",
        "\n",
        "  def unittest_backward(self):\n",
        "    mesVerbose(True, \"@@@ test backward\", \"nnModule > unittest_backward:\")\n",
        "    in_shape = self.getInShape()\n",
        "    model = self.getModel()\n",
        "    x = torch.rand(in_shape[0], in_shape[1], in_shape[2], in_shape[3])\n",
        "    out = self.forward(x)\n",
        "    loss = nn.MSELoss()(out, torch.rand(*out.shape))\n",
        "\n",
        "    print(\"example_mse_loss:\", type(loss), loss)\n",
        "    optimizer = optim.Adam(list(model.parameters()), lr=2e-5, weight_decay=0)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(\"backward finish, the weights (state) of current instance CAN changed!\")\n",
        "    params = list(model.parameters())\n",
        "    print(\"parameters():\")\n",
        "    for p in params: print(type(p), p.shape)\n",
        "\n",
        "  def unittest_summary(self):\n",
        "    mesVerbose(True, \"@@@ test summary\", \"nnModule > unittest_summary:\")\n",
        "    in_shape = self.getInShape()\n",
        "    model = self.getModel().copy()\n",
        "    x = torch.rand(in_shape[0], in_shape[1], in_shape[2], in_shape[3])\n",
        "    for layer in model:\n",
        "      print(\"\\tin_shape:\", type(x), x.shape)\n",
        "      print(type(layer), sys.getsizeof(layer))\n",
        "      x = layer(x)\n",
        "    print(\"out_shape:\", type(x), x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5MIjFYCk4pp"
      },
      "source": [
        "##### blcoks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.495263Z",
          "iopub.status.busy": "2024-03-10T03:46:58.494890Z",
          "iopub.status.idle": "2024-03-10T03:46:58.506457Z",
          "shell.execute_reply": "2024-03-10T03:46:58.505472Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.495210Z"
        },
        "trusted": true,
        "id": "r5mESj1bk4pq"
      },
      "outputs": [],
      "source": [
        "class ConvWithBatchNorm(nn.Module):\n",
        "  \"\"\"Conv layer with batch norm and leaky relu\"\"\"\n",
        "\n",
        "  def __init__(self, in_c: int, out_c: int, k_size: int, stride=1, negative_slope=0.1):\n",
        "    super(ConvWithBatchNorm, self).__init__()\n",
        "\n",
        "    padding = k_size // 2\n",
        "    layers = nn.ModuleList()\n",
        "    layers += [nn.Conv2d(in_c, out_c, k_size, stride=stride, padding=padding, bias=False)]\n",
        "    layers += [nn.BatchNorm2d(num_features=out_c)]\n",
        "    layers += [nn.LeakyReLU(negative_slope=negative_slope)]\n",
        "    self.layers = layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.507903Z",
          "iopub.status.busy": "2024-03-10T03:46:58.507592Z",
          "iopub.status.idle": "2024-03-10T03:46:58.515625Z",
          "shell.execute_reply": "2024-03-10T03:46:58.514681Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.507874Z"
        },
        "trusted": true,
        "id": "Nj0k_pkUk4pq"
      },
      "outputs": [],
      "source": [
        "class BottleNeckBlock(nn.Module):\n",
        "  \"\"\"Block of 1x1 reduction layers followed by 3x3 conv. layer\"\"\"\n",
        "\n",
        "  def __init__(self, in_c: int, out_ces: tuple, num_repeat: int):\n",
        "    super(BottleNeckBlock, self).__init__()\n",
        "\n",
        "    out_1x1 = out_ces[0]\n",
        "    out_3x3 = out_ces[1]\n",
        "    layers = nn.ModuleList()\n",
        "    for i in range(num_repeat):\n",
        "      layers += [nn.Conv2d(in_c, out_1x1, 1, stride=1, padding=0, bias=False)]\n",
        "      layers += [nn.Conv2d(out_1x1, out_3x3, 3, stride=1, padding=1, bias=False)]\n",
        "    self.layers = layers\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7_sw1k3k4pr"
      },
      "source": [
        "##### YoloBackbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.519558Z",
          "iopub.status.busy": "2024-03-10T03:46:58.519284Z",
          "iopub.status.idle": "2024-03-10T03:46:58.528646Z",
          "shell.execute_reply": "2024-03-10T03:46:58.527761Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.519535Z"
        },
        "trusted": true,
        "id": "0NT7ITSLk4pr"
      },
      "outputs": [],
      "source": [
        "class YoloBackbone(nnModule):\n",
        "  \"\"\"YOLO backbone extract feature from the input\"\"\"\n",
        "\n",
        "  def __init__(self, in_shpae: tuple, backbone_config=YOLO_BACKBONE_ARCHITECTURE):\n",
        "    super(YoloBackbone, self).__init__()\n",
        "    self.setInShape(in_shpae)\n",
        "    model = self.getModel()\n",
        "    x = torch.rand(in_shpae[0], in_shpae[1], in_shpae[2], in_shpae[3])\n",
        "    for i, config in enumerate(backbone_config):\n",
        "      if type(config) == tuple:\n",
        "        out_c, k_size, stride, _ = config\n",
        "        model += [ConvWithBatchNorm(in_c=x.shape[1], out_c=out_c, k_size=k_size, stride=stride, negative_slope=0.1)]\n",
        "        x = model[-1](x)\n",
        "\n",
        "      elif type(config) == str:\n",
        "        model += [nn.MaxPool2d(kernel_size=2, stride=2, padding=0)]\n",
        "        x = model[-1](x)\n",
        "\n",
        "      elif type(config) == list:\n",
        "        out_ces, num_repeat = config\n",
        "        model += [BottleNeckBlock(x.shape[1], out_ces, num_repeat)]\n",
        "        x = model[-1](x)\n",
        "    self.setOutShape(x.shape)\n",
        "    self.setModel(model=model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.getModel():\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7uJuu6Ak4ps",
        "outputId": "3a42565d-4051-4e38-fc4b-980ca5074d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: nnModule > unittest_backward: @@@ test backward\n",
            "example_mse_loss: <class 'torch.Tensor'> tensor(0.3335, grad_fn=<MseLossBackward0>)\n",
            "backward finish, the weights (state) of instance CAN changed!\n",
            "parameters():\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 7, 7])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([192, 64, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([192])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([192])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 192, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 128, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 1024, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 1024, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "YoloBackbone((4, 3, 224, 224)).unittest_backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyoC7afXk4ps"
      },
      "source": [
        "##### YoloOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "qXT-6EExk4ps"
      },
      "outputs": [],
      "source": [
        "YOLO_OUT_ARCHITECTURE = [(4096, 0.1), 0.5, (2040, 0.1), 0.5, (1024, 0.1), 0.5, (GRID_SIZE * GRID_SIZE * (NUM_BOXES * 5 + NUM_CLASSES), 0.1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:58.943891Z",
          "iopub.status.busy": "2024-03-10T03:46:58.943518Z",
          "iopub.status.idle": "2024-03-10T03:46:58.954778Z",
          "shell.execute_reply": "2024-03-10T03:46:58.953883Z",
          "shell.execute_reply.started": "2024-03-10T03:46:58.943858Z"
        },
        "trusted": true,
        "id": "rqf_8jvrk4pt"
      },
      "outputs": [],
      "source": [
        "class YoloOutput(nnModule):\n",
        "  \"\"\"YOLO last convolution and FC layers to produce prediction\"\"\"\n",
        "\n",
        "  def __init__(self, in_shape: tuple):\n",
        "    super(YoloOutput, self).__init__()\n",
        "    self.setInShape(in_shape=in_shape)\n",
        "    x = torch.rand(in_shape[0], in_shape[1], in_shape[2], in_shape[3])\n",
        "    model = nn.ModuleList()\n",
        "    model += [ConvWithBatchNorm(in_shape[1], out_c=1024, k_size=3),\n",
        "              ConvWithBatchNorm(1024, out_c=1024, k_size=3),\n",
        "              ConvWithBatchNorm(1024, out_c=1024, k_size=3),\n",
        "              ConvWithBatchNorm(1024, out_c=1024, k_size=3),\n",
        "              nn.Flatten()]\n",
        "    for layer in model: x = layer(x)\n",
        "\n",
        "    for i, config in enumerate(YOLO_OUT_ARCHITECTURE):\n",
        "      if type(config) == tuple:\n",
        "        out_f, slop = config\n",
        "        model += [nn.Linear(in_features=x.shape[1], out_features=out_f), nn.LeakyReLU(negative_slope=slop)]\n",
        "        x = model[-1](model[-2](x))\n",
        "      else:\n",
        "        p = config\n",
        "        model += [nn.Dropout(p=0.5)]\n",
        "        x = model[-1](x)\n",
        "\n",
        "    self.setOutShape(x.shape)\n",
        "    self.setModel(model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.getModel():\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtBJgOFhk4pt",
        "outputId": "9ba49b90-093b-41ff-90ec-93431a959b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: nnModule > unittest_backward: @@@ test backward\n",
            "example_mse_loss: <class 'torch.Tensor'> tensor(0.3051, grad_fn=<MseLossBackward0>)\n",
            "backward finish, the weights (state) of instance CAN changed!\n",
            "parameters():\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([4096, 50176])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([4096])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2040, 4096])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2040])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 2040])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([637, 1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([637])\n"
          ]
        }
      ],
      "source": [
        "YoloOutput((16, 1024, 7, 7)).unittest_backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cthP7XbNk4pt"
      },
      "source": [
        "##### YoloV1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:59.980516Z",
          "iopub.status.busy": "2024-03-10T03:46:59.979894Z",
          "iopub.status.idle": "2024-03-10T03:46:59.989798Z",
          "shell.execute_reply": "2024-03-10T03:46:59.988801Z",
          "shell.execute_reply.started": "2024-03-10T03:46:59.980480Z"
        },
        "trusted": true,
        "id": "ynLF5B34k4pt"
      },
      "outputs": [],
      "source": [
        "class YoloV1(nnModule):\n",
        "  \"\"\"End-to-end YOLO network\"\"\"\n",
        "\n",
        "  def __init__(self, in_shape: tuple):\n",
        "    super(YoloV1, self).__init__()\n",
        "    self.setInShape(in_shape)\n",
        "\n",
        "    x = torch.rand(in_shape[0], in_shape[1], in_shape[2], in_shape[3])\n",
        "    yolo_backbone = YoloBackbone(in_shape)\n",
        "    x = yolo_backbone(x)\n",
        "    yolo_output = YoloOutput(in_shape=x.shape)\n",
        "    x = yolo_output(x)\n",
        "\n",
        "    self.setOutShape(x.shape)\n",
        "    model = nn.ModuleList()\n",
        "    model += [yolo_backbone, yolo_output]\n",
        "    self.setModel(model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.getModel():\n",
        "      x = layer(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiyS607xk4pu",
        "outputId": "2a457892-93b1-4ba2-c0d0-fc1ec331defe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: nnModule > unittest_backward: @@@ test backward\n",
            "example_mse_loss: <class 'torch.Tensor'> tensor(0.3054, grad_fn=<MseLossBackward0>)\n",
            "backward finish, the weights (state) of instance CAN changed!\n",
            "parameters():\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 3, 7, 7])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([192, 64, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([192])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([192])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 192, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([128, 128, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 128, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 256, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([256, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 256, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 512, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 1024, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 1024, 1, 1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 512, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 1024, 3, 3])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([4096, 50176])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([4096])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2040, 4096])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2040])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024, 2040])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([637, 1024])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([637])\n"
          ]
        }
      ],
      "source": [
        "YoloV1((16, 3, 224, 224)).unittest_backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4pfk6uRk4pu"
      },
      "source": [
        "### YoloLoss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection_over_union(boxes_preds, boxes_labels, box_format='midpoint'):\n",
        "  \"\"\"\n",
        "  Calculates intersection over union\n",
        "\n",
        "  Parameters:\n",
        "      boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
        "      boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n",
        "      box_format (str): midpoint/corners, if boxes are (x,y,w,h) or (x1,y1,x2,y2) respectively.\n",
        "\n",
        "  Returns:\n",
        "      tensor: Intersection over union for all examples\n",
        "  \"\"\"\n",
        "  # boxes_preds shape is (N, 4)\n",
        "  # boxes_labels shape is (N, 4)\n",
        "\n",
        "  if box_format == 'midpoint':\n",
        "      box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
        "      box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
        "      box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
        "      box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
        "\n",
        "      box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
        "      box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
        "      box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
        "      box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
        "\n",
        "  if box_format == 'corners':\n",
        "      box1_x1 = boxes_preds[..., 0:1]\n",
        "      box1_y1 = boxes_preds[..., 1:2]\n",
        "      box1_x2 = boxes_preds[..., 2:3]\n",
        "      box1_y2 = boxes_preds[..., 3:4]\n",
        "\n",
        "      box2_x1 = boxes_labels[..., 0:1]\n",
        "      box2_y1 = boxes_labels[..., 1:2]\n",
        "      box2_x2 = boxes_labels[..., 2:3]\n",
        "      box2_y2 = boxes_labels[..., 3:4]\n",
        "\n",
        "  x1 = torch.max(box1_x1, box2_x1)\n",
        "  y1 = torch.max(box1_y1, box2_y1)\n",
        "  x2 = torch.min(box1_x2, box2_x2)\n",
        "  y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "  #&&& .clamp(0) is for the case when they don't intersect. Since when they don't intersect, one of these will be negative so that should become 0\n",
        "  intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
        "  box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
        "  box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
        "  return intersection / (box1_area + box2_area - intersection + 1e-6)\n"
      ],
      "metadata": {
        "id": "aZpFmnwzNzRw"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPS = 1e-6\n",
        "def sign_sqrt(pred):\n",
        "  return torch.sign(pred) * torch.sqrt(torch.abs(pred + EPS))\n",
        "#&&& tai 0 khong co dao ham cua abs"
      ],
      "metadata": {
        "id": "vDYzFCrMpqu7"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:46:59.991771Z",
          "iopub.status.busy": "2024-03-10T03:46:59.991405Z",
          "iopub.status.idle": "2024-03-10T03:47:00.014653Z",
          "shell.execute_reply": "2024-03-10T03:47:00.013718Z",
          "shell.execute_reply.started": "2024-03-10T03:46:59.991737Z"
        },
        "trusted": true,
        "id": "q8AApm83k4pu"
      },
      "outputs": [],
      "source": [
        "class YoloLoss(nn.Module):\n",
        "  def __init__(self, coord_c=5, noobj_c=0.5):\n",
        "    super(YoloLoss, self).__init__()\n",
        "    self.COORD = coord_c\n",
        "    self.NOOBJ = noobj_c\n",
        "    self.mse = nn.MSELoss(reduction=\"sum\")\n",
        "\n",
        "  def setLoss(self, some_loss): self.some_loss = some_loss\n",
        "  def getLoss(self): return self.some_loss\n",
        "\n",
        "  def forward(self, predictions: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    predictions = predictions.reshape((-1, GRID_SIZE, GRID_SIZE, NUM_BOXES * 5 + NUM_CLASSES))\n",
        "    exists_box = target[..., [4]]\n",
        "    iou_b1 = intersection_over_union(\n",
        "        predictions[...,0:4], target[..., 0:4])\n",
        "    iou_b2 = intersection_over_union(\n",
        "        predictions[..., 5:9], target[..., 0:4])\n",
        "    bestbox = torch.where(iou_b1 >= iou_b2, 0, 1)\n",
        "\n",
        "    # class loss\n",
        "    class_loss = self.mse(\n",
        "      exists_box * predictions[..., 10:],\n",
        "      exists_box * target[..., 5:])\n",
        "\n",
        "    # obj loss\n",
        "    pred_box = (\n",
        "        (1-bestbox) * predictions[..., [4]] + (bestbox) * predictions[..., [9]]\n",
        "    )\n",
        "    object_loss = self.mse(\n",
        "      exists_box * pred_box,\n",
        "      exists_box * target[..., [4]]\n",
        "    )\n",
        "\n",
        "    # coor loss\n",
        "    pred_box = (\n",
        "        (1-bestbox) * predictions[..., 0:4] + (bestbox) * predictions[..., 5:9]\n",
        "    )\n",
        "    true_box = target[..., 0:4]\n",
        "    pred_box[..., 2:4] = sign_sqrt(pred_box[..., 2:4])\n",
        "    true_box[..., 2:4] = sign_sqrt(true_box[..., 2:4])\n",
        "    coor_loss = self.mse(\n",
        "      #exists_box * pred_box, end_dim=-2),\n",
        "      #exists_box * true_box, end_dim=-2),\n",
        "      exists_box * pred_box, exists_box * true_box\n",
        "    )\n",
        "\n",
        "    # no obj loss\n",
        "    no_obj_loss = self.mse(\n",
        "      (1 - exists_box) * predictions[..., [4]], (1 - exists_box) * target[..., [4]]\n",
        "    )\n",
        "    no_obj_loss += self.mse(\n",
        "      (1 - exists_box) * predictions[..., [9]], (1 - exists_box) * target[..., [4]]\n",
        "    )\n",
        "    self.setLoss((class_loss, coor_loss, object_loss, no_obj_loss))\n",
        "    return class_loss + object_loss + self.COORD * coor_loss + self.NOOBJ * no_obj_loss\n",
        "\n",
        "  def unittest_loss_backloss(self):\n",
        "    mesVerbose(True, \"@@@ test loss and backloss\", \"YoloLoss > unittest_loss_backloss:\")\n",
        "    model = YoloV1(in_shape=IN_SHAPE)\n",
        "    x = torch.rand(*IN_SHAPE)\n",
        "    out = model(x)\n",
        "    y = torch.rand(*OUT_SHAPE)\n",
        "    loss = self.forward(out, y)\n",
        "\n",
        "    print(\"example_loss:\", type(loss), loss)\n",
        "    optimizer = optim.Adam(list(model.parameters()), lr=2e-5, weight_decay=0)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(\"loss and backloss finish\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YoloLoss().unittest_loss_backloss()"
      ],
      "metadata": {
        "id": "FZHO6m97QZkg",
        "outputId": "d2762672-a62f-49cb-e4f5-d923786d277a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: YoloLoss > unittest_loss_backloss: @@@ test loss and backloss\n",
            "example_loss: <class 'torch.Tensor'> tensor(595.8547, grad_fn=<AddBackward0>)\n",
            "loss and backloss finish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUZaJA6Kk4pw"
      },
      "source": [
        "### DataLoad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:47:01.077602Z",
          "iopub.status.busy": "2024-03-10T03:47:01.077296Z",
          "iopub.status.idle": "2024-03-10T03:47:01.112647Z",
          "shell.execute_reply": "2024-03-10T03:47:01.111724Z",
          "shell.execute_reply.started": "2024-03-10T03:47:01.077577Z"
        },
        "trusted": true,
        "id": "Ffxoi8Bgk4pw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from xml.etree import ElementTree\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "class_names = ['apple', 'banana', 'orange']\n",
        "\n",
        "class DataLoad(data.Dataset):\n",
        "  def utest_loaddata(self):\n",
        "    mesVerbose(True, \"@@@ test load data\", \"DataLoad(nn.Dataset) > utest_loaddata:\")\n",
        "    print(\"repeat:\", self.repeat)\n",
        "    print(\"is aug:\", self.aug)\n",
        "    over(self.imgs, \"imgs = \")\n",
        "    over(self.labels, \"labels = \")\n",
        "\n",
        "  def utest_getdata(self):\n",
        "    mesVerbose(True, \"@@@ test get data\", \"DataLoad(nn.Dataset) > utest_getdata:\")\n",
        "    x, y = self.__getitem__(0)\n",
        "    over(x, \"x = \")\n",
        "    over(y, \"y = \")\n",
        "\n",
        "  def __init__(self, file_dir, repeat, aug=False) -> None:\n",
        "    super().__init__()\n",
        "    self.repeat, self.aug = repeat, aug\n",
        "    dataframe = self.get_dataframe(file_dir=file_dir)\n",
        "    self.imgs, self.labels = self.load_dataset(dataframe, input_shape=(224, 224, 3), #!!!\n",
        "                                                grid_size=GRID_SIZE) # np.ndarray\n",
        "    # repeat\n",
        "    for i in range(repeat):\n",
        "      self.imgs = np.concatenate((self.imgs, self.imgs), axis=0)\n",
        "      self.labels = np.concatenate((self.labels, self.labels), axis=0)\n",
        "    # aug\n",
        "    if(aug == True):\n",
        "      for i, img in enumerate(self.imgs):\n",
        "        label = self.labels[i]\n",
        "        self.imgs[i], self.labels[i] = self._apply_augmentation(img, label, seed=RANDOM_STATE)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      x, y = self.imgs[idx], self.labels[idx] # np.ndarray\n",
        "      x, y = tf.convert_to_tensor(x), tf.convert_to_tensor(y) # tf.tensor\n",
        "      x = torch.tensor(x.numpy(), dtype=torch.float32)  # torch.tensor\n",
        "      y = torch.tensor(y.numpy(), dtype=torch.float32)\n",
        "      return x, y\n",
        "\n",
        "\n",
        "  def get_dataframe(self, file_dir):\n",
        "    \"\"\"\n",
        "    Get the train/val/test dataframe which contains image\n",
        "    file names and annotations files. If `phase = train',\n",
        "    return train and val set\n",
        "    :param file_dir: File directory to create dataframe\n",
        "    :return file_df: Train or test dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    img_files = [os.path.join(file_dir, img_file) for img_file\n",
        "                 in sorted(os.listdir(file_dir)) if img_file[-4:] == '.jpg']\n",
        "    annot_files = [img_file[:-4] + '.xml' for img_file in img_files]\n",
        "\n",
        "    img_file_series = pd.Series(img_files, name='Image_file')\n",
        "    annot_file_series = pd.Series(annot_files, name='Annotation_file')\n",
        "    file_df = pd.DataFrame(pd.concat([img_file_series, annot_file_series], axis=1))\n",
        "    return file_df\n",
        "\n",
        "  def prepare_image(self, filename, input_shape):\n",
        "    \"\"\"\n",
        "    Resize image to expected dimension, and opt. apply some random transformation.\n",
        "    :param filename: File name\n",
        "    :param input_shape: Shape expected by the model (image will be resize accordingly)\n",
        "    :return : 3D image array, pixel values from [0., 1.]\n",
        "    \"\"\"\n",
        "\n",
        "    img = img_to_array(load_img(filename, target_size=input_shape)) / 255.\n",
        "    img = np.einsum('ijk->kij', img)\n",
        "    return img\n",
        "\n",
        "  def convert_to_xywh(self, bboxes):\n",
        "    \"\"\"\n",
        "    Convert list of (xmin, ymin, xmax, ymax) to\n",
        "    (x_center, y_center, box_width, box_height)\n",
        "    :param bboxes: List of bounding boxes, each has 4\n",
        "    values (xmin, ymin, xmax, ymax)\n",
        "    :return boxes: List of bounding boxes, each has 4\n",
        "    values (x_center, y_center, box_width, box_height)\n",
        "    \"\"\"\n",
        "\n",
        "    boxes = list()\n",
        "    for box in bboxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "\n",
        "        # Compute width and height of box\n",
        "        box_width = xmax - xmin\n",
        "        box_height = ymax - ymin\n",
        "\n",
        "        # Compute x, y center\n",
        "        x_center = int(xmin + (box_width / 2))\n",
        "        y_center = int(ymin + (box_height / 2))\n",
        "\n",
        "        boxes.append((x_center, y_center, box_width, box_height))\n",
        "\n",
        "    return boxes\n",
        "\n",
        "  def extract_annotation_file(self, filename):\n",
        "    \"\"\"\n",
        "    Extract bounding boxes from an annotation file\n",
        "    :param filename: Annotation file name\n",
        "    :return boxes: List of bounding boxes in image, each box has\n",
        "    4 values (x_center, y_center, box_width, box_height)\n",
        "    :return classes: List of classes in image\n",
        "    :return width: Width of image\n",
        "    :return height: Height of image\n",
        "    \"\"\"\n",
        "\n",
        "    # Load and parse the file\n",
        "    tree = ElementTree.parse(filename)\n",
        "    # Get the root of the document\n",
        "    root = tree.getroot()\n",
        "    boxes = list()\n",
        "    classes = list()\n",
        "\n",
        "    # Extract each bounding box\n",
        "    for box in root.findall('.//object'):\n",
        "        cls = class_names.index(box.find('name').text)\n",
        "        xmin = int(box.find('bndbox/xmin').text)\n",
        "        ymin = int(box.find('bndbox/ymin').text)\n",
        "        xmax = int(box.find('bndbox/xmax').text)\n",
        "        ymax = int(box.find('bndbox/ymax').text)\n",
        "        coors = (xmin, ymin, xmax, ymax)\n",
        "        boxes.append(coors)\n",
        "        classes.append(cls)\n",
        "\n",
        "    boxes = self.convert_to_xywh(boxes)\n",
        "\n",
        "    # Get width and height of an image\n",
        "    width = int(root.find('.//size/width').text)\n",
        "    height = int(root.find('.//size/height').text)\n",
        "\n",
        "    # Some annotation files have set width and height by 0,\n",
        "    # so we need to load image and get it width and height\n",
        "    if (width == 0) or (height == 0):\n",
        "        img = load_img(filename[:-4] + '.jpg')\n",
        "        width, height = img.width, img.height\n",
        "\n",
        "    return boxes, classes, width, height\n",
        "\n",
        "  def convert_bboxes_to_tensor(self, bboxes, classes, img_width, img_height, grid_size=7):\n",
        "    \"\"\"\n",
        "    Convert list of bounding boxes to tensor target\n",
        "    :param bboxes: List of bounding boxes in image, each box has\n",
        "    4 values (x_center, y_center, box_width, box_height)\n",
        "    :param classes: List of class in image\n",
        "    :param img_width: Image's width\n",
        "    :param img_height: Image's height\n",
        "    :param grid_size: Grid size\n",
        "    :return target: Target tensor (grid_size x grid_size x (5 + num_classes))\n",
        "    \"\"\"\n",
        "\n",
        "    num_classes = len(class_names)\n",
        "    target = np.zeros(shape=(grid_size, grid_size, 5 + num_classes), dtype=np.float32)\n",
        "\n",
        "    for idx, bbox in enumerate(bboxes):\n",
        "        x_center, y_center, width, height = bbox\n",
        "\n",
        "        # Compute size of each cell in grid\n",
        "        cell_w, cell_h = img_width / grid_size, img_height / grid_size\n",
        "\n",
        "        # Determine cell i, j of bounding box\n",
        "        i, j = int(y_center / cell_h), int(x_center / cell_w)\n",
        "\n",
        "        # Compute value of x_center and y_center in cell\n",
        "        x, y = (x_center / cell_w) - j, (y_center / cell_h) - i\n",
        "\n",
        "        # Normalize width and height of bounding box\n",
        "        w_norm, h_norm = width / img_width, height / img_height\n",
        "\n",
        "        # Add bounding box to tensor\n",
        "        # Set x, y, w, h\n",
        "        target[i, j, :4] += (x, y, w_norm, h_norm)\n",
        "        # Set obj score\n",
        "        target[i, j, 4] = 1.\n",
        "        # Set class dist.\n",
        "        target[i, j, 5 + classes[idx]] = 1.\n",
        "    return target\n",
        "\n",
        "  def load_dataset(self, dataframe, input_shape, grid_size=7):\n",
        "    \"\"\"\n",
        "    Load img and target tensor\n",
        "    :param dataframe: Dataframe contains img files and annotation files\n",
        "    :param input_shape: Shape expected by the model (image will be resize accordingly)\n",
        "    :param grid_size: Grid size\n",
        "    :return dataset: Iterable dataset\n",
        "    \"\"\"\n",
        "\n",
        "    imgs, targets = list(), list()\n",
        "\n",
        "    for _, row in tqdm(dataframe.iterrows()):\n",
        "        img = self.prepare_image(row.Image_file, input_shape)\n",
        "        target = self.extract_annotation_file(row.Annotation_file)\n",
        "        target = self.convert_bboxes_to_tensor(*target, grid_size)\n",
        "        imgs.append(img)\n",
        "        targets.append(target)\n",
        "\n",
        "    imgs = np.array(imgs)\n",
        "    targets = np.array(targets)\n",
        "    return imgs, targets\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices((imgs, targets))\n",
        "    # return dataset\n",
        "\n",
        "  def _apply_augmentation(self, image, target, seed=None):\n",
        "    \"\"\"\n",
        "    Apply random brightness and saturation on image\n",
        "    :param image: Image to augment\n",
        "    :param target: Target tensor\n",
        "    :param seed: Seed for random operation\n",
        "    :return : Processed data\n",
        "    \"\"\"\n",
        "\n",
        "    # Random bright & saturation change\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1, seed=seed)\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5, seed=seed)\n",
        "\n",
        "    # Keeping pixel values in check\n",
        "    image = tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "    return image, target\n",
        "\n",
        "  def load_dataset_from_df(self, dataframe, batch_size=32, num_repeat=None, shuffle=False,\n",
        "                         input_shape=(448, 448, 3), grid_size=7, augment=False,\n",
        "                         seed=None):\n",
        "    \"\"\"\n",
        "    Instantiate dataset\n",
        "    :param dataframe: Dataframe contains img files and annotation files\n",
        "    :param batch_size: Batch size\n",
        "    :param num_epochs: Number of epochs (to repeat the iteration - infinite if None)\n",
        "    :param shuffle: Flag to shuffle the dataset (if True)\n",
        "    :param input_shape: Shape of the processed image\n",
        "    :param grid_size: Grid size\n",
        "    :param augment: Flag to apply some random augmentations to the image\n",
        "    :param seed: Random seed for operation\n",
        "    :return : Iterable dataset\n",
        "    \"\"\"\n",
        "\n",
        "    apply_augmentation = partial(self._apply_augmentation, seed=seed)\n",
        "    dataset = self.load_dataset(dataframe, input_shape, grid_size)\n",
        "    ### !!!\n",
        "    dataset = dataset.repeat(num_repeat)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(1000, seed)\n",
        "    if augment:\n",
        "        dataset = dataset.map(apply_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oNYux31ctz8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08cb52b3-52e7-4c8b-ce4f-4b803052b52b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:47:01.129581Z",
          "iopub.status.busy": "2024-03-10T03:47:01.129181Z",
          "iopub.status.idle": "2024-03-10T03:47:04.085670Z",
          "shell.execute_reply": "2024-03-10T03:47:04.084832Z",
          "shell.execute_reply.started": "2024-03-10T03:47:01.129547Z"
        },
        "trusted": true,
        "id": "g7aCKNwWk4py",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5329ae-bc0b-4693-9c4e-3c52a8c90122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "27it [00:00, 59.43it/s]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "240it [00:04, 49.59it/s]\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/My_Laptop_Data/fruits_dataset/train'\n",
        "dataload = DataLoad(train_dir, aug=False, repeat=4)\n",
        "train_df = dataload.get_dataframe(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataload.utest_loaddata()\n",
        "dataload.utest_getdata()"
      ],
      "metadata": {
        "id": "bPpZvNzCS5Ct",
        "outputId": "bd75707c-b6e4-416d-c39f-3dc7b3fc5c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: DataLoad(nn.Dataset) > utest_loaddata: @@@ test load data\n",
            "repeat: 4\n",
            "is aug: False\n",
            "__verbose__: imgs =  (<class 'numpy.ndarray'>, (3840, 3, 224, 224), '2312110240Bytes')\n",
            "__verbose__: labels =  (<class 'numpy.ndarray'>, (3840, 7, 7, 8), '6021280Bytes')\n",
            "__verbose__: DataLoad(nn.Dataset) > utest_getdata: @@@ test get data\n",
            "__verbose__: x =  (<class 'torch.Tensor'>, torch.Size([3, 224, 224]), '80Bytes')\n",
            "__verbose__: y =  (<class 'torch.Tensor'>, torch.Size([7, 7, 8]), '80Bytes')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:47:05.169394Z",
          "iopub.status.busy": "2024-03-10T03:47:05.169010Z",
          "iopub.status.idle": "2024-03-10T03:47:05.173886Z",
          "shell.execute_reply": "2024-03-10T03:47:05.172894Z",
          "shell.execute_reply.started": "2024-03-10T03:47:05.169351Z"
        },
        "trusted": true,
        "id": "jNUQ__YOk4p0"
      },
      "outputs": [],
      "source": [
        "# Assuming train_dataset is your training dataset\n",
        "# train_loader = DataLoader(dataset=dataload, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True, prefetch_factor=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:47:05.175464Z",
          "iopub.status.busy": "2024-03-10T03:47:05.175168Z",
          "iopub.status.idle": "2024-03-10T03:47:05.180973Z",
          "shell.execute_reply": "2024-03-10T03:47:05.180101Z",
          "shell.execute_reply.started": "2024-03-10T03:47:05.175440Z"
        },
        "trusted": true,
        "id": "QX3qRl7Pk4p0"
      },
      "outputs": [],
      "source": [
        "# Assuming train_dataset is your training dataset\n",
        "train_loader = data.DataLoader(dataset=dataload, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "over(train_loader, \"train_loader=\")"
      ],
      "metadata": {
        "id": "Ds3HlEGU1OnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2fc7f7-ef1f-49f0-f8dd-f32539b4b982"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_loader= (<class 'torch.utils.data.dataloader.DataLoader'>, 'no-shape', '48Bytes')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9fYLiHwk4qC"
      },
      "source": [
        "### training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:48:45.967884Z",
          "iopub.status.busy": "2024-03-10T03:48:45.967230Z",
          "iopub.status.idle": "2024-03-10T03:48:45.981803Z",
          "shell.execute_reply": "2024-03-10T03:48:45.980885Z",
          "shell.execute_reply.started": "2024-03-10T03:48:45.967829Z"
        },
        "trusted": true,
        "id": "oUiDcu5jk4qF"
      },
      "outputs": [],
      "source": [
        "def train_fn(train_loader, model, optimizer, loss_fn):\n",
        "  loop = tqdm(train_loader, leave=True)\n",
        "  mean_loss = []\n",
        "\n",
        "  for batch_idx, (x, y) in enumerate(loop):\n",
        "    mesVerbose(True, \"@@@ --- training loop ---\", \"train_fn:\")\n",
        "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "    out = model(x).to(DEVICE)\n",
        "    loss = loss_fn(out, y).to(DEVICE)\n",
        "\n",
        "    print(\"some_loss = \", loss_fn.getLoss())\n",
        "    print(\"loss = \", loss)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Mean loss of epoch was {sum(mean_loss) / len(mean_loss)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-10T03:49:32.743596Z",
          "iopub.status.busy": "2024-03-10T03:49:32.742756Z",
          "iopub.status.idle": "2024-03-10T03:49:32.770236Z",
          "shell.execute_reply": "2024-03-10T03:49:32.769009Z",
          "shell.execute_reply.started": "2024-03-10T03:49:32.743565Z"
        },
        "trusted": true,
        "id": "zZTm0-S-k4qG"
      },
      "outputs": [],
      "source": [
        "train_loader = data.DataLoader(dataset=dataload, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "model = YoloV1(in_shape=IN_SHAPE).to(DEVICE)\n",
        "optimizer = optim.Adam(list(model.parameters()), lr=2e-5, weight_decay=0)\n",
        "loss_fn = YoloLoss().to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_fn(train_loader, model, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "euzVKy3--qkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddba94f-8788-4d20-e153-635de3ae90ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/960 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.1005, grad_fn=<MseLossBackward0>), tensor(12.1832, grad_fn=<MseLossBackward0>), tensor(6.6087, grad_fn=<MseLossBackward0>), tensor(0.9023, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(75.0766, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/960 [00:10<2:44:04, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.8425, grad_fn=<MseLossBackward0>), tensor(12.2627, grad_fn=<MseLossBackward0>), tensor(9.5611, grad_fn=<MseLossBackward0>), tensor(1.4174, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(81.4257, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/960 [00:17<2:16:15,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(15.5544, grad_fn=<MseLossBackward0>), tensor(16.9474, grad_fn=<MseLossBackward0>), tensor(14.3654, grad_fn=<MseLossBackward0>), tensor(1.8594, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(115.5863, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/960 [00:24<2:05:11,  7.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.4622, grad_fn=<MseLossBackward0>), tensor(5.7498, grad_fn=<MseLossBackward0>), tensor(3.4173, grad_fn=<MseLossBackward0>), tensor(2.9412, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(37.0993, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 4/960 [00:31<2:00:17,  7.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.4199, grad_fn=<MseLossBackward0>), tensor(7.1768, grad_fn=<MseLossBackward0>), tensor(6.6364, grad_fn=<MseLossBackward0>), tensor(3.7139, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(50.7973, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 5/960 [00:38<1:55:59,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.5051, grad_fn=<MseLossBackward0>), tensor(9.6283, grad_fn=<MseLossBackward0>), tensor(5.2060, grad_fn=<MseLossBackward0>), tensor(4.9820, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(61.3437, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 6/960 [00:45<1:56:42,  7.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.6361, grad_fn=<MseLossBackward0>), tensor(6.4325, grad_fn=<MseLossBackward0>), tensor(6.3931, grad_fn=<MseLossBackward0>), tensor(6.1146, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(48.2488, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 7/960 [00:52<1:54:37,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(11.3606, grad_fn=<MseLossBackward0>), tensor(14.7051, grad_fn=<MseLossBackward0>), tensor(10.6731, grad_fn=<MseLossBackward0>), tensor(6.0892, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(98.6039, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 8/960 [01:00<1:54:28,  7.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.8289, grad_fn=<MseLossBackward0>), tensor(8.4887, grad_fn=<MseLossBackward0>), tensor(6.4916, grad_fn=<MseLossBackward0>), tensor(6.4910, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(59.0098, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/960 [01:07<1:53:34,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.7151, grad_fn=<MseLossBackward0>), tensor(4.4179, grad_fn=<MseLossBackward0>), tensor(7.2053, grad_fn=<MseLossBackward0>), tensor(8.3654, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(40.1925, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 10/960 [01:14<1:53:48,  7.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.2671, grad_fn=<MseLossBackward0>), tensor(5.3679, grad_fn=<MseLossBackward0>), tensor(3.8683, grad_fn=<MseLossBackward0>), tensor(12.0098, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(39.9797, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 11/960 [01:21<1:52:05,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.4200, grad_fn=<MseLossBackward0>), tensor(1.6826, grad_fn=<MseLossBackward0>), tensor(3.3464, grad_fn=<MseLossBackward0>), tensor(10.4831, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(20.4210, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 12/960 [01:29<1:59:04,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.7593, grad_fn=<MseLossBackward0>), tensor(5.7892, grad_fn=<MseLossBackward0>), tensor(4.0791, grad_fn=<MseLossBackward0>), tensor(9.4731, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(43.5208, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 13/960 [01:37<1:57:30,  7.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.9574, grad_fn=<MseLossBackward0>), tensor(7.0805, grad_fn=<MseLossBackward0>), tensor(6.7521, grad_fn=<MseLossBackward0>), tensor(10.9639, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(54.5941, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 14/960 [01:44<1:54:56,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(2.9030, grad_fn=<MseLossBackward0>), tensor(2.9617, grad_fn=<MseLossBackward0>), tensor(3.4661, grad_fn=<MseLossBackward0>), tensor(11.7590, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(27.0572, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 15/960 [01:51<1:53:39,  7.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(12.0976, grad_fn=<MseLossBackward0>), tensor(12.0223, grad_fn=<MseLossBackward0>), tensor(8.8133, grad_fn=<MseLossBackward0>), tensor(8.8743, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(85.4593, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 16/960 [01:58<1:52:30,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(16.6057, grad_fn=<MseLossBackward0>), tensor(18.2832, grad_fn=<MseLossBackward0>), tensor(15.4628, grad_fn=<MseLossBackward0>), tensor(10.3314, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(128.6501, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 17/960 [02:05<1:51:46,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.5495, grad_fn=<MseLossBackward0>), tensor(9.8846, grad_fn=<MseLossBackward0>), tensor(7.4567, grad_fn=<MseLossBackward0>), tensor(11.7607, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(70.3097, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 18/960 [02:12<1:51:35,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.4467, grad_fn=<MseLossBackward0>), tensor(8.9702, grad_fn=<MseLossBackward0>), tensor(8.0823, grad_fn=<MseLossBackward0>), tensor(10.0928, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(68.4264, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 19/960 [02:20<1:56:28,  7.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(11.6881, grad_fn=<MseLossBackward0>), tensor(11.8008, grad_fn=<MseLossBackward0>), tensor(8.3630, grad_fn=<MseLossBackward0>), tensor(10.0998, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(84.1052, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 20/960 [02:27<1:54:13,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.7680, grad_fn=<MseLossBackward0>), tensor(2.6611, grad_fn=<MseLossBackward0>), tensor(2.2824, grad_fn=<MseLossBackward0>), tensor(10.4533, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(24.5825, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 21/960 [02:34<1:53:19,  7.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.8554, grad_fn=<MseLossBackward0>), tensor(6.2886, grad_fn=<MseLossBackward0>), tensor(6.4888, grad_fn=<MseLossBackward0>), tensor(12.9257, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(52.2502, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 22/960 [02:43<2:00:14,  7.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.3443, grad_fn=<MseLossBackward0>), tensor(4.1024, grad_fn=<MseLossBackward0>), tensor(3.8092, grad_fn=<MseLossBackward0>), tensor(10.8305, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(34.0808, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 23/960 [02:50<1:58:23,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.8026, grad_fn=<MseLossBackward0>), tensor(2.8924, grad_fn=<MseLossBackward0>), tensor(4.0461, grad_fn=<MseLossBackward0>), tensor(13.2471, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.9341, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 24/960 [02:57<1:54:44,  7.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.9271, grad_fn=<MseLossBackward0>), tensor(2.6806, grad_fn=<MseLossBackward0>), tensor(2.1391, grad_fn=<MseLossBackward0>), tensor(10.9879, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(24.9632, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 25/960 [03:04<1:54:16,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.7840, grad_fn=<MseLossBackward0>), tensor(9.7662, grad_fn=<MseLossBackward0>), tensor(5.9846, grad_fn=<MseLossBackward0>), tensor(12.0241, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(68.6118, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 26/960 [03:11<1:52:04,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.5689, grad_fn=<MseLossBackward0>), tensor(1.2356, grad_fn=<MseLossBackward0>), tensor(3.3488, grad_fn=<MseLossBackward0>), tensor(14.1934, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.1922, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 27/960 [03:18<1:51:57,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.1278, grad_fn=<MseLossBackward0>), tensor(7.9704, grad_fn=<MseLossBackward0>), tensor(7.8128, grad_fn=<MseLossBackward0>), tensor(11.6307, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(62.6077, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 28/960 [03:25<1:49:47,  7.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.6286, grad_fn=<MseLossBackward0>), tensor(8.0336, grad_fn=<MseLossBackward0>), tensor(6.2711, grad_fn=<MseLossBackward0>), tensor(13.9957, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(59.0655, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 29/960 [03:32<1:48:38,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.6161, grad_fn=<MseLossBackward0>), tensor(1.6525, grad_fn=<MseLossBackward0>), tensor(2.6201, grad_fn=<MseLossBackward0>), tensor(11.6006, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(20.2989, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 30/960 [03:39<1:49:00,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.8029, grad_fn=<MseLossBackward0>), tensor(5.2918, grad_fn=<MseLossBackward0>), tensor(4.6656, grad_fn=<MseLossBackward0>), tensor(13.0920, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(43.4735, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 31/960 [03:46<1:49:07,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.6738, grad_fn=<MseLossBackward0>), tensor(6.5697, grad_fn=<MseLossBackward0>), tensor(7.0899, grad_fn=<MseLossBackward0>), tensor(11.4306, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(53.3272, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 32/960 [03:53<1:49:25,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(11.4431, grad_fn=<MseLossBackward0>), tensor(8.6464, grad_fn=<MseLossBackward0>), tensor(9.5685, grad_fn=<MseLossBackward0>), tensor(9.9500, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(69.2185, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 33/960 [04:00<1:48:29,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.7722, grad_fn=<MseLossBackward0>), tensor(3.0848, grad_fn=<MseLossBackward0>), tensor(4.0640, grad_fn=<MseLossBackward0>), tensor(9.3592, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.9396, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 34/960 [04:07<1:49:44,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.5617, grad_fn=<MseLossBackward0>), tensor(7.9692, grad_fn=<MseLossBackward0>), tensor(9.4646, grad_fn=<MseLossBackward0>), tensor(10.1204, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(63.9327, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 35/960 [04:14<1:48:44,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.8890, grad_fn=<MseLossBackward0>), tensor(1.5291, grad_fn=<MseLossBackward0>), tensor(2.2672, grad_fn=<MseLossBackward0>), tensor(9.3205, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(19.4618, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 36/960 [04:21<1:49:08,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.6910, grad_fn=<MseLossBackward0>), tensor(6.8340, grad_fn=<MseLossBackward0>), tensor(9.0305, grad_fn=<MseLossBackward0>), tensor(12.2163, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(58.9996, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 37/960 [04:28<1:46:17,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.7607, grad_fn=<MseLossBackward0>), tensor(6.0595, grad_fn=<MseLossBackward0>), tensor(5.2308, grad_fn=<MseLossBackward0>), tensor(9.0927, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(46.8353, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 38/960 [04:35<1:49:00,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.1077, grad_fn=<MseLossBackward0>), tensor(6.0342, grad_fn=<MseLossBackward0>), tensor(4.2094, grad_fn=<MseLossBackward0>), tensor(10.3251, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(44.6508, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 39/960 [04:42<1:46:14,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.7246, grad_fn=<MseLossBackward0>), tensor(4.0813, grad_fn=<MseLossBackward0>), tensor(3.8147, grad_fn=<MseLossBackward0>), tensor(7.6571, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(31.7741, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 40/960 [04:50<1:49:51,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.7436, grad_fn=<MseLossBackward0>), tensor(7.8431, grad_fn=<MseLossBackward0>), tensor(7.7992, grad_fn=<MseLossBackward0>), tensor(9.0631, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(59.2900, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 41/960 [04:56<1:47:22,  7.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(13.5066, grad_fn=<MseLossBackward0>), tensor(11.6634, grad_fn=<MseLossBackward0>), tensor(10.7775, grad_fn=<MseLossBackward0>), tensor(12.7442, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(88.9733, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 42/960 [05:04<1:51:12,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.4516, grad_fn=<MseLossBackward0>), tensor(6.3792, grad_fn=<MseLossBackward0>), tensor(5.8584, grad_fn=<MseLossBackward0>), tensor(11.2956, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(48.8538, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 43/960 [05:11<1:46:41,  6.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.4311, grad_fn=<MseLossBackward0>), tensor(4.5930, grad_fn=<MseLossBackward0>), tensor(5.8003, grad_fn=<MseLossBackward0>), tensor(10.6373, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(40.5151, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 44/960 [05:18<1:50:01,  7.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.6755, grad_fn=<MseLossBackward0>), tensor(7.9056, grad_fn=<MseLossBackward0>), tensor(7.3496, grad_fn=<MseLossBackward0>), tensor(12.7761, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(59.9413, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 45/960 [05:25<1:46:34,  6.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.2376, grad_fn=<MseLossBackward0>), tensor(4.5857, grad_fn=<MseLossBackward0>), tensor(3.9524, grad_fn=<MseLossBackward0>), tensor(11.2016, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(39.7195, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 46/960 [05:32<1:49:09,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.2148, grad_fn=<MseLossBackward0>), tensor(1.7056, grad_fn=<MseLossBackward0>), tensor(5.1784, grad_fn=<MseLossBackward0>), tensor(9.8340, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(22.8384, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 47/960 [05:39<1:46:08,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.4315, grad_fn=<MseLossBackward0>), tensor(4.6080, grad_fn=<MseLossBackward0>), tensor(5.0381, grad_fn=<MseLossBackward0>), tensor(8.5540, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(37.7867, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 48/960 [05:47<1:49:05,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.4777, grad_fn=<MseLossBackward0>), tensor(3.7224, grad_fn=<MseLossBackward0>), tensor(6.5737, grad_fn=<MseLossBackward0>), tensor(7.1673, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(36.2473, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 49/960 [05:53<1:45:46,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.9086, grad_fn=<MseLossBackward0>), tensor(10.5664, grad_fn=<MseLossBackward0>), tensor(10.4974, grad_fn=<MseLossBackward0>), tensor(11.1694, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(79.8224, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 50/960 [06:01<1:48:49,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.8300, grad_fn=<MseLossBackward0>), tensor(5.3253, grad_fn=<MseLossBackward0>), tensor(6.7186, grad_fn=<MseLossBackward0>), tensor(8.2121, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(45.2811, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 51/960 [06:07<1:46:42,  7.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.4340, grad_fn=<MseLossBackward0>), tensor(4.3308, grad_fn=<MseLossBackward0>), tensor(7.3770, grad_fn=<MseLossBackward0>), tensor(10.2239, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(42.5771, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 52/960 [06:15<1:48:53,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.2879, grad_fn=<MseLossBackward0>), tensor(5.6794, grad_fn=<MseLossBackward0>), tensor(7.5539, grad_fn=<MseLossBackward0>), tensor(10.3796, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(51.4286, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 53/960 [06:22<1:46:16,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.4067, grad_fn=<MseLossBackward0>), tensor(3.5784, grad_fn=<MseLossBackward0>), tensor(4.1186, grad_fn=<MseLossBackward0>), tensor(8.2017, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(32.5183, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 54/960 [06:29<1:48:43,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(12.4448, grad_fn=<MseLossBackward0>), tensor(8.4181, grad_fn=<MseLossBackward0>), tensor(12.2789, grad_fn=<MseLossBackward0>), tensor(8.0166, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(70.8223, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 55/960 [06:38<1:54:37,  7.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.8780, grad_fn=<MseLossBackward0>), tensor(1.8749, grad_fn=<MseLossBackward0>), tensor(3.7662, grad_fn=<MseLossBackward0>), tensor(7.3712, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(20.7042, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 56/960 [06:45<1:50:59,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.1837, grad_fn=<MseLossBackward0>), tensor(3.9074, grad_fn=<MseLossBackward0>), tensor(4.5518, grad_fn=<MseLossBackward0>), tensor(6.4701, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(32.5074, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 57/960 [06:52<1:49:49,  7.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.7737, grad_fn=<MseLossBackward0>), tensor(2.3063, grad_fn=<MseLossBackward0>), tensor(3.9026, grad_fn=<MseLossBackward0>), tensor(6.2125, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(23.3141, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 58/960 [06:58<1:47:19,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.9429, grad_fn=<MseLossBackward0>), tensor(7.1064, grad_fn=<MseLossBackward0>), tensor(8.9982, grad_fn=<MseLossBackward0>), tensor(4.8011, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(53.8733, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 59/960 [07:05<1:46:38,  7.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.8287, grad_fn=<MseLossBackward0>), tensor(3.6674, grad_fn=<MseLossBackward0>), tensor(6.9544, grad_fn=<MseLossBackward0>), tensor(6.4754, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(35.3576, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 60/960 [07:12<1:44:54,  6.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.9438, grad_fn=<MseLossBackward0>), tensor(4.6432, grad_fn=<MseLossBackward0>), tensor(5.7989, grad_fn=<MseLossBackward0>), tensor(5.7133, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(36.8153, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 61/960 [07:19<1:45:34,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.8458, grad_fn=<MseLossBackward0>), tensor(2.2270, grad_fn=<MseLossBackward0>), tensor(2.1332, grad_fn=<MseLossBackward0>), tensor(6.0474, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.1377, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 62/960 [07:26<1:44:30,  6.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.1194, grad_fn=<MseLossBackward0>), tensor(8.3978, grad_fn=<MseLossBackward0>), tensor(9.1226, grad_fn=<MseLossBackward0>), tensor(5.5068, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(60.9844, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 63/960 [07:33<1:45:09,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.5866, grad_fn=<MseLossBackward0>), tensor(2.8270, grad_fn=<MseLossBackward0>), tensor(4.8881, grad_fn=<MseLossBackward0>), tensor(5.8638, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(27.5418, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 64/960 [07:40<1:43:17,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.2876, grad_fn=<MseLossBackward0>), tensor(6.2332, grad_fn=<MseLossBackward0>), tensor(5.8896, grad_fn=<MseLossBackward0>), tensor(4.2930, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(45.4895, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 65/960 [07:47<1:44:02,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.2628, grad_fn=<MseLossBackward0>), tensor(0.7718, grad_fn=<MseLossBackward0>), tensor(3.2535, grad_fn=<MseLossBackward0>), tensor(6.1333, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(13.4419, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 66/960 [07:54<1:42:56,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(13.1749, grad_fn=<MseLossBackward0>), tensor(8.4898, grad_fn=<MseLossBackward0>), tensor(11.8241, grad_fn=<MseLossBackward0>), tensor(8.7053, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(71.8006, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 67/960 [08:01<1:43:20,  6.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.2495, grad_fn=<MseLossBackward0>), tensor(4.4076, grad_fn=<MseLossBackward0>), tensor(6.3701, grad_fn=<MseLossBackward0>), tensor(6.3255, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(38.8203, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 68/960 [08:08<1:42:52,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.4904, grad_fn=<MseLossBackward0>), tensor(4.6505, grad_fn=<MseLossBackward0>), tensor(6.0179, grad_fn=<MseLossBackward0>), tensor(5.8304, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(37.6762, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 69/960 [08:15<1:43:41,  6.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.8522, grad_fn=<MseLossBackward0>), tensor(3.6173, grad_fn=<MseLossBackward0>), tensor(4.5294, grad_fn=<MseLossBackward0>), tensor(8.4871, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(32.7119, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 70/960 [08:22<1:42:51,  6.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.6427, grad_fn=<MseLossBackward0>), tensor(6.8342, grad_fn=<MseLossBackward0>), tensor(7.1877, grad_fn=<MseLossBackward0>), tensor(6.6042, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(53.3034, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 71/960 [08:29<1:44:15,  7.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(2.5027, grad_fn=<MseLossBackward0>), tensor(2.5331, grad_fn=<MseLossBackward0>), tensor(2.8515, grad_fn=<MseLossBackward0>), tensor(5.9897, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.0144, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 72/960 [08:36<1:42:42,  6.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.0637, grad_fn=<MseLossBackward0>), tensor(2.7221, grad_fn=<MseLossBackward0>), tensor(2.3089, grad_fn=<MseLossBackward0>), tensor(9.5386, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(23.7526, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 73/960 [08:43<1:44:51,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.1100, grad_fn=<MseLossBackward0>), tensor(10.7198, grad_fn=<MseLossBackward0>), tensor(11.7164, grad_fn=<MseLossBackward0>), tensor(7.6676, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(79.2593, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 74/960 [08:50<1:42:38,  6.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(2.5845, grad_fn=<MseLossBackward0>), tensor(3.0105, grad_fn=<MseLossBackward0>), tensor(2.2000, grad_fn=<MseLossBackward0>), tensor(8.9313, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(24.3028, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 75/960 [08:57<1:45:33,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.7922, grad_fn=<MseLossBackward0>), tensor(6.0769, grad_fn=<MseLossBackward0>), tensor(5.9722, grad_fn=<MseLossBackward0>), tensor(6.3764, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(47.3372, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 76/960 [09:04<1:42:53,  6.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.1056, grad_fn=<MseLossBackward0>), tensor(2.3160, grad_fn=<MseLossBackward0>), tensor(2.4352, grad_fn=<MseLossBackward0>), tensor(7.3423, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.7920, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 77/960 [09:12<1:45:28,  7.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.8297, grad_fn=<MseLossBackward0>), tensor(3.2039, grad_fn=<MseLossBackward0>), tensor(2.9471, grad_fn=<MseLossBackward0>), tensor(11.0192, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.3060, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 78/960 [09:18<1:42:26,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.8314, grad_fn=<MseLossBackward0>), tensor(9.4914, grad_fn=<MseLossBackward0>), tensor(8.7063, grad_fn=<MseLossBackward0>), tensor(8.9236, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(69.4563, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 79/960 [09:26<1:44:51,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.9109, grad_fn=<MseLossBackward0>), tensor(5.7593, grad_fn=<MseLossBackward0>), tensor(4.4014, grad_fn=<MseLossBackward0>), tensor(6.3199, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(40.2687, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 80/960 [09:32<1:41:19,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.5546, grad_fn=<MseLossBackward0>), tensor(3.0854, grad_fn=<MseLossBackward0>), tensor(5.5748, grad_fn=<MseLossBackward0>), tensor(6.4832, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.7979, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 81/960 [09:39<1:43:41,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.5672, grad_fn=<MseLossBackward0>), tensor(6.7676, grad_fn=<MseLossBackward0>), tensor(10.3054, grad_fn=<MseLossBackward0>), tensor(6.3069, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(57.8638, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 82/960 [09:46<1:40:13,  6.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.1023, grad_fn=<MseLossBackward0>), tensor(1.4599, grad_fn=<MseLossBackward0>), tensor(2.3084, grad_fn=<MseLossBackward0>), tensor(9.9274, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(17.6739, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 83/960 [09:53<1:43:03,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.5465, grad_fn=<MseLossBackward0>), tensor(4.3883, grad_fn=<MseLossBackward0>), tensor(4.7967, grad_fn=<MseLossBackward0>), tensor(7.6416, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(34.1056, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 84/960 [10:00<1:39:50,  6.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.4018, grad_fn=<MseLossBackward0>), tensor(2.8247, grad_fn=<MseLossBackward0>), tensor(4.5256, grad_fn=<MseLossBackward0>), tensor(10.9971, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(29.5495, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 85/960 [10:07<1:42:59,  7.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.1036, grad_fn=<MseLossBackward0>), tensor(2.7430, grad_fn=<MseLossBackward0>), tensor(4.6562, grad_fn=<MseLossBackward0>), tensor(7.0613, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.0054, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 86/960 [10:14<1:40:04,  6.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.0066, grad_fn=<MseLossBackward0>), tensor(5.8365, grad_fn=<MseLossBackward0>), tensor(6.7470, grad_fn=<MseLossBackward0>), tensor(6.3933, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(48.1325, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 87/960 [10:21<1:43:27,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.7435, grad_fn=<MseLossBackward0>), tensor(5.3456, grad_fn=<MseLossBackward0>), tensor(3.8574, grad_fn=<MseLossBackward0>), tensor(6.2370, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(38.4476, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 88/960 [10:28<1:40:02,  6.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.3999, grad_fn=<MseLossBackward0>), tensor(6.9632, grad_fn=<MseLossBackward0>), tensor(9.1782, grad_fn=<MseLossBackward0>), tensor(5.4781, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(55.1331, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 89/960 [10:37<1:49:27,  7.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.8196, grad_fn=<MseLossBackward0>), tensor(3.4281, grad_fn=<MseLossBackward0>), tensor(3.7831, grad_fn=<MseLossBackward0>), tensor(6.7163, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(29.1014, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 90/960 [10:43<1:44:50,  7.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.4143, grad_fn=<MseLossBackward0>), tensor(7.5514, grad_fn=<MseLossBackward0>), tensor(5.7832, grad_fn=<MseLossBackward0>), tensor(8.9085, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(56.4090, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 91/960 [10:51<1:47:42,  7.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.1200, grad_fn=<MseLossBackward0>), tensor(3.1577, grad_fn=<MseLossBackward0>), tensor(5.4017, grad_fn=<MseLossBackward0>), tensor(7.6497, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(30.1351, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 92/960 [10:58<1:43:20,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.9071, grad_fn=<MseLossBackward0>), tensor(4.5782, grad_fn=<MseLossBackward0>), tensor(5.6217, grad_fn=<MseLossBackward0>), tensor(6.3130, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(37.5763, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 93/960 [11:05<1:45:51,  7.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(7.0289, grad_fn=<MseLossBackward0>), tensor(7.4431, grad_fn=<MseLossBackward0>), tensor(6.9462, grad_fn=<MseLossBackward0>), tensor(7.7002, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(55.0406, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 94/960 [11:12<1:41:44,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(11.0107, grad_fn=<MseLossBackward0>), tensor(7.0781, grad_fn=<MseLossBackward0>), tensor(9.8581, grad_fn=<MseLossBackward0>), tensor(5.4145, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(58.9666, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 95/960 [11:20<1:44:51,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.7591, grad_fn=<MseLossBackward0>), tensor(4.6628, grad_fn=<MseLossBackward0>), tensor(5.0511, grad_fn=<MseLossBackward0>), tensor(6.5233, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(37.3860, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 96/960 [11:26<1:41:03,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.3877, grad_fn=<MseLossBackward0>), tensor(8.9363, grad_fn=<MseLossBackward0>), tensor(9.1651, grad_fn=<MseLossBackward0>), tensor(5.2081, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(66.8386, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 97/960 [11:34<1:44:45,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(2.7704, grad_fn=<MseLossBackward0>), tensor(2.4430, grad_fn=<MseLossBackward0>), tensor(2.9698, grad_fn=<MseLossBackward0>), tensor(7.8039, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.8572, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 98/960 [11:41<1:41:32,  7.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.3573, grad_fn=<MseLossBackward0>), tensor(3.9644, grad_fn=<MseLossBackward0>), tensor(4.0065, grad_fn=<MseLossBackward0>), tensor(6.6689, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(31.5204, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 99/960 [11:48<1:44:57,  7.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(11.4678, grad_fn=<MseLossBackward0>), tensor(7.5915, grad_fn=<MseLossBackward0>), tensor(9.1564, grad_fn=<MseLossBackward0>), tensor(4.3406, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(60.7519, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 100/960 [11:55<1:40:59,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.9293, grad_fn=<MseLossBackward0>), tensor(2.3770, grad_fn=<MseLossBackward0>), tensor(3.6361, grad_fn=<MseLossBackward0>), tensor(5.7540, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(23.3276, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 101/960 [12:03<1:44:17,  7.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.5948, grad_fn=<MseLossBackward0>), tensor(8.4576, grad_fn=<MseLossBackward0>), tensor(9.1352, grad_fn=<MseLossBackward0>), tensor(5.0769, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(63.5567, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 102/960 [12:09<1:41:04,  7.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.6574, grad_fn=<MseLossBackward0>), tensor(3.2424, grad_fn=<MseLossBackward0>), tensor(8.1967, grad_fn=<MseLossBackward0>), tensor(4.6258, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(32.3787, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 103/960 [12:17<1:44:25,  7.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.2032, grad_fn=<MseLossBackward0>), tensor(1.4546, grad_fn=<MseLossBackward0>), tensor(2.7303, grad_fn=<MseLossBackward0>), tensor(6.1247, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(17.2688, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 104/960 [12:24<1:41:32,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.5166, grad_fn=<MseLossBackward0>), tensor(3.3635, grad_fn=<MseLossBackward0>), tensor(6.9716, grad_fn=<MseLossBackward0>), tensor(5.4154, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(32.0134, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 105/960 [12:32<1:44:12,  7.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.3960, grad_fn=<MseLossBackward0>), tensor(3.0746, grad_fn=<MseLossBackward0>), tensor(4.0887, grad_fn=<MseLossBackward0>), tensor(6.0785, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.8971, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 106/960 [12:38<1:39:49,  7.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.1122, grad_fn=<MseLossBackward0>), tensor(5.3081, grad_fn=<MseLossBackward0>), tensor(5.9876, grad_fn=<MseLossBackward0>), tensor(6.0460, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(43.6634, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 107/960 [12:46<1:42:58,  7.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.2245, grad_fn=<MseLossBackward0>), tensor(1.8792, grad_fn=<MseLossBackward0>), tensor(4.3225, grad_fn=<MseLossBackward0>), tensor(5.5186, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(22.7022, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 108/960 [12:52<1:39:50,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.3145, grad_fn=<MseLossBackward0>), tensor(2.3373, grad_fn=<MseLossBackward0>), tensor(2.9825, grad_fn=<MseLossBackward0>), tensor(7.0577, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(23.5124, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 109/960 [13:00<1:43:10,  7.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.4157, grad_fn=<MseLossBackward0>), tensor(1.1371, grad_fn=<MseLossBackward0>), tensor(2.6622, grad_fn=<MseLossBackward0>), tensor(8.8457, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(18.1865, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 110/960 [13:07<1:40:20,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.8121, grad_fn=<MseLossBackward0>), tensor(5.3345, grad_fn=<MseLossBackward0>), tensor(5.4557, grad_fn=<MseLossBackward0>), tensor(6.4731, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(41.1769, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 111/960 [13:14<1:42:59,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.2600, grad_fn=<MseLossBackward0>), tensor(3.2180, grad_fn=<MseLossBackward0>), tensor(3.2404, grad_fn=<MseLossBackward0>), tensor(4.7867, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(25.9837, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 112/960 [13:21<1:40:03,  7.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.5752, grad_fn=<MseLossBackward0>), tensor(3.3063, grad_fn=<MseLossBackward0>), tensor(2.8121, grad_fn=<MseLossBackward0>), tensor(5.4162, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(26.6272, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 113/960 [13:29<1:42:45,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.1483, grad_fn=<MseLossBackward0>), tensor(4.3824, grad_fn=<MseLossBackward0>), tensor(3.6237, grad_fn=<MseLossBackward0>), tensor(6.0917, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(32.7300, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 114/960 [13:35<1:40:11,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(9.1782, grad_fn=<MseLossBackward0>), tensor(3.9565, grad_fn=<MseLossBackward0>), tensor(7.2767, grad_fn=<MseLossBackward0>), tensor(5.9837, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(39.2293, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 115/960 [13:43<1:41:17,  7.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.8790, grad_fn=<MseLossBackward0>), tensor(2.4557, grad_fn=<MseLossBackward0>), tensor(2.5811, grad_fn=<MseLossBackward0>), tensor(5.3420, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.4094, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 116/960 [13:50<1:39:09,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(12.5185, grad_fn=<MseLossBackward0>), tensor(7.6561, grad_fn=<MseLossBackward0>), tensor(9.4949, grad_fn=<MseLossBackward0>), tensor(5.5775, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(63.0828, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 117/960 [13:57<1:40:38,  7.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(11.0092, grad_fn=<MseLossBackward0>), tensor(7.0123, grad_fn=<MseLossBackward0>), tensor(10.0882, grad_fn=<MseLossBackward0>), tensor(5.3367, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(58.8272, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 118/960 [14:04<1:38:56,  7.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.8297, grad_fn=<MseLossBackward0>), tensor(3.2087, grad_fn=<MseLossBackward0>), tensor(4.4584, grad_fn=<MseLossBackward0>), tensor(5.1691, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(28.9163, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 119/960 [14:11<1:40:00,  7.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.7607, grad_fn=<MseLossBackward0>), tensor(4.1780, grad_fn=<MseLossBackward0>), tensor(4.3662, grad_fn=<MseLossBackward0>), tensor(5.5343, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(34.7843, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 120/960 [14:18<1:38:23,  7.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(10.8619, grad_fn=<MseLossBackward0>), tensor(9.7161, grad_fn=<MseLossBackward0>), tensor(10.7138, grad_fn=<MseLossBackward0>), tensor(4.9190, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(72.6158, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 121/960 [14:26<1:41:33,  7.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.3729, grad_fn=<MseLossBackward0>), tensor(3.0904, grad_fn=<MseLossBackward0>), tensor(6.1279, grad_fn=<MseLossBackward0>), tensor(4.6186, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(30.2621, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 122/960 [14:33<1:42:38,  7.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.7150, grad_fn=<MseLossBackward0>), tensor(4.8754, grad_fn=<MseLossBackward0>), tensor(6.8039, grad_fn=<MseLossBackward0>), tensor(5.4012, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(40.5966, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 123/960 [14:40<1:39:39,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.0472, grad_fn=<MseLossBackward0>), tensor(2.0225, grad_fn=<MseLossBackward0>), tensor(2.9045, grad_fn=<MseLossBackward0>), tensor(7.7059, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(21.9173, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 124/960 [14:47<1:39:14,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.3634, grad_fn=<MseLossBackward0>), tensor(2.8385, grad_fn=<MseLossBackward0>), tensor(3.5993, grad_fn=<MseLossBackward0>), tensor(4.4468, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(25.3786, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 125/960 [14:54<1:37:24,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(6.4146, grad_fn=<MseLossBackward0>), tensor(1.9396, grad_fn=<MseLossBackward0>), tensor(4.1993, grad_fn=<MseLossBackward0>), tensor(5.6979, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(23.1607, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 126/960 [15:01<1:38:46,  7.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(5.4592, grad_fn=<MseLossBackward0>), tensor(1.9571, grad_fn=<MseLossBackward0>), tensor(4.3621, grad_fn=<MseLossBackward0>), tensor(6.7974, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(23.0054, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 127/960 [15:08<1:37:14,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.5831, grad_fn=<MseLossBackward0>), tensor(0.3152, grad_fn=<MseLossBackward0>), tensor(2.7089, grad_fn=<MseLossBackward0>), tensor(6.3324, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(11.0340, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 128/960 [15:15<1:38:41,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.4541, grad_fn=<MseLossBackward0>), tensor(5.7055, grad_fn=<MseLossBackward0>), tensor(4.8401, grad_fn=<MseLossBackward0>), tensor(7.2186, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(45.4308, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 129/960 [15:22<1:36:21,  6.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(2.0927, grad_fn=<MseLossBackward0>), tensor(2.3312, grad_fn=<MseLossBackward0>), tensor(2.4470, grad_fn=<MseLossBackward0>), tensor(5.0877, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(18.7393, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 130/960 [15:29<1:37:41,  7.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(4.8014, grad_fn=<MseLossBackward0>), tensor(3.7430, grad_fn=<MseLossBackward0>), tensor(5.0586, grad_fn=<MseLossBackward0>), tensor(5.5609, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(31.3556, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▎        | 131/960 [15:36<1:35:00,  6.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.0165, grad_fn=<MseLossBackward0>), tensor(5.1103, grad_fn=<MseLossBackward0>), tensor(6.1276, grad_fn=<MseLossBackward0>), tensor(6.4891, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(42.9400, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 132/960 [15:43<1:36:53,  7.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.2119, grad_fn=<MseLossBackward0>), tensor(4.7470, grad_fn=<MseLossBackward0>), tensor(4.2139, grad_fn=<MseLossBackward0>), tensor(8.0792, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(35.2002, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 133/960 [15:49<1:34:18,  6.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.2580, grad_fn=<MseLossBackward0>), tensor(7.5886, grad_fn=<MseLossBackward0>), tensor(7.5619, grad_fn=<MseLossBackward0>), tensor(5.0213, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(56.2736, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 134/960 [15:57<1:37:20,  7.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(3.0253, grad_fn=<MseLossBackward0>), tensor(1.5843, grad_fn=<MseLossBackward0>), tensor(1.6620, grad_fn=<MseLossBackward0>), tensor(6.8294, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(16.0234, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 135/960 [16:03<1:35:06,  6.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__verbose__: train_fn: @@@ --- training loop ---\n",
            "some_loss =  (tensor(8.1957, grad_fn=<MseLossBackward0>), tensor(4.2775, grad_fn=<MseLossBackward0>), tensor(6.0589, grad_fn=<MseLossBackward0>), tensor(9.0396, grad_fn=<AddBackward0>))\n",
            "loss =  tensor(40.1619, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHcY1XR9k4qG"
      },
      "source": [
        "### End"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4569729,
          "sourceId": 7803789,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}